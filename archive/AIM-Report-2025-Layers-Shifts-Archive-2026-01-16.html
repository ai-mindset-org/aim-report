<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AIM Annual Report 2025 - Layers & Shifts Archive</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'IBM Plex Mono', monospace;
      background: #0A0A0A;
      color: #F5F5F5;
      line-height: 1.6;
      padding: 2rem;
    }
    .container { max-width: 1200px; margin: 0 auto; }
    .slide {
      background: #171717;
      border: 1px solid #262626;
      border-radius: 8px;
      padding: 3rem;
      margin-bottom: 3rem;
      page-break-inside: avoid;
    }
    .slide.dark { background: #0A0A0A; border-color: #DC2626; }
    h1 {
      font-size: 2.5rem;
      font-weight: 900;
      text-transform: uppercase;
      margin-bottom: 1rem;
      color: #F5F5F5;
    }
    h2 {
      font-size: 1.5rem;
      color: #DC2626;
      margin: 2rem 0 1rem;
      font-weight: 700;
    }
    h3 {
      font-size: 1.2rem;
      color: #A3A3A3;
      margin: 1.5rem 0 0.5rem;
      font-weight: 600;
    }
    p { margin-bottom: 1rem; }
    strong { color: #DC2626; font-weight: 700; }
    a { color: #DC2626; text-decoration: none; }
    a:hover { text-decoration: underline; }
    ul, ol { margin-left: 2rem; margin-bottom: 1rem; }
    li { margin-bottom: 0.5rem; }
    .meta {
      font-size: 0.9rem;
      color: #737373;
      margin-bottom: 2rem;
      padding-bottom: 1rem;
      border-bottom: 1px solid #262626;
    }
    .section-divider {
      background: linear-gradient(135deg, #DC2626 0%, #991B1B 100%);
      color: white;
      text-align: center;
      padding: 4rem 2rem;
      margin: 4rem 0;
      border-radius: 12px;
    }
    @media print {
      body { background: white; color: black; }
      .slide { border: 1px solid #ccc; page-break-inside: avoid; }
      .slide.dark { background: #f5f5f5; }
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="slide section-divider">
      <h1>AIM Annual Report 2025</h1>
      <p style="font-size: 1.2rem; margin-top: 1rem;">The Context Gap · Layers & Shifts Archive</p>
      <p style="margin-top: 2rem; font-size: 0.9rem; opacity: 0.8;">Exported: 2026-01-16</p>
    </div>

    <div class="slide dark">
      <div class="meta">Slide 1 · Layout: story-scroll</div>
      <h1>the context gap</h1>
      <h3>ai is accelerating. humans are changing.</h3>
      <div class="content">
        2025 wasn't just a year in the ai calendar. it was the moment <strong></strong>. we called this report the context gap because it identifies the primary fracture in modern civilization: the distance between the volume of data a machine can generate and the amount of meaning a human can integrate without losing their agency, their sanity, or their will.</p><p><strong></strong> ai is accelerating. humans are buffering.</p><p>we are solving a fundamental crisis: <strong></strong>. in a world where generating content, code, and ideas is effectively free, the act of verifying them has become a luxury. we are currently paying a <strong></strong> with our time and attention. if you cannot audit what the algorithm proposes, you are no longer a leader—you are a passenger.</p><p>this report is your perimeter defense against: <strong></strong> (cognitive paralysis), <strong></strong> ($67 billion in annual losses), <strong></strong> (decisions by agents with no accountability), and <strong></strong> (ai training on ai-generated data).</p><p>we organize the 11 shifts into 4 layers because <strong></strong> - it cascades through civilization in a specific order.</p><p><strong></strong> - physics, economics, and power. <strong></strong> - reasoning, knowledge, discovery. <strong></strong> - coding, matter, defense. <strong></strong> - narrative and intimacy.</p><p>each shift creates a <strong></strong> ↔ <strong></strong> ↔ <strong></strong>. this isn't a hype deck, a moral panic, or a consulting pdf. this is a map of fractures in our reality.
      </div>
    </div>
  
    <div class="slide dark">
      <div class="meta">Slide 2 · Layout: center</div>
      <h1>layer i: foundation</h1>
      <h3>physics, economics, and power</h3>
      <div class="content">
        the physical and economic base. energy infrastructure, agentic labor, data sovereignty.</p><p><strong></strong> can we power it? can we afford it? <strong></strong>
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 3 · Layout: shift-scroll</div>
      <h1>shift 01: chip supply ➔ power supply</h1>
      <h3>the energy wall</h3>
      <div class="content">
        <strong></strong> <strong></strong> ai demand for data center power projected to grow <strong></strong>. demand for compute is growing faster than power grid capacity. the physical grid cannot be built fast enough to support ai expansion. <strong></strong> the focus shifts from raw compute to "inference efficiency" as the critical metric. more compute doesn't equal more value if it can't be powered. Data centers are reopening coal plants and demanding nuclear reactors.</p><p><strong></strong> The energy wall.</p><p><strong></strong> <strong></strong> users face the reality that complex reasoning has a physical toll — every ai query consumes water and generates co2. the disconnect between "green ai" corporate promises and "greed ai" reality.</p><p><strong></strong> Guilt computing.</p><p><strong></strong> the disconnect between infinite "digital ideas" and hard "physical matter". while we imagine a billion agents, we cannot power them.</p><p>The gap between business desire to deploy AI everywhere and the planet's physical inability to support it.</p><p><strong></strong>
<li><strong></strong> AI energy demand surge by 2030 (<a href="" target="_blank"></a> / <a href="" target="_blank"></a>)
<li><strong></strong> Gap: $500B infrastructure vs $12B consumer spend (<a href="" target="_blank"></a> / <a href="" target="_blank"></a>)
<li><strong></strong> Total AI infrastructure requirement (<a href="" target="_blank"></a> / Sam Altman)</p><p><strong></strong>
<li><a href="" target="_blank"></a>
<li>Focus shifts from raw compute (FLOPs) to <a href="" target="_blank"></a>. as critical metric
<li><a href="" target="_blank"></a>. — Brian Janous
<li>Tech giants reviving <a href="" target="_blank"></a> (Three Mile Island for Microsoft) and obsolete fossil fuel plants</p><p><strong></strong> Energy Infrastructure, Nuclear Power, Data Centers, Cloud Computing</p><p>source: "A painful power crunch that could constrain AI's growth likely lies ahead" (Brian Janous) — Goldman Sachs | https://www.goldmansachs.com/intelligence/pages/gen-ai-too-much-spend-too-little-benefit.html
source: Microsoft reopening Three Mile Island nuclear plant for AI power — Reuters | https://www.reuters.com/markets/deals/constellation-inks-power-supply-deal-with-microsoft-2024-09-20/
source: AI poised to drive 160% increase in data center power demand — Goldman Sachs | https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand
source: 2025 State of Consumer AI ($12B spend) — Menlo Ventures | https://menlovc.com/perspective/2025-the-state-of-consumer-ai/
source: The physical grid cannot be built fast enough — IT Brief | https://itbrief.news/story/when-the-grid-becomes-the-bottleneck-the-real-threat-to-ai-deployment
source: Intelligence per Watt — Snorkel AI / McKinsey | https://snorkel.ai/blog/intelligence-per-watt-a-new-metric-for-ais-future/
source: $7T Total AI infrastructure requirement — McKinsey | https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/the-cost-of-compute-a-7-trillion-dollar-race-to-scale-data-centers
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 4 · Layout: shift-scroll</div>
      <h1>shift 02: assistant ➔ autonomous coworker</h1>
      <h3>the displacement</h3>
      <div class="content">
        <strong></strong> <strong></strong> transition from "assistant" to "autonomous coworker". agents receive wallets (x402 protocol), tools (mcp), and "hr for ai".</p><p><strong></strong> saas model shifts to agents that execute complete workflows. from selling "software licenses" to "executed outcomes".</p><p><strong></strong> one ai assistant replaced 700 full-time agents, slashed resolution time (11m → 2m), drove $40m profit, and achieved 25% fewer repeat inquiries than humans.</p><p><strong></strong> The shift from chat to delegation.</p><p><strong></strong> <strong></strong> "if an agent can do my job, who am i?". the psychological toll of moving from "creator" to "manager of agents".</p><p><strong></strong> humans lose the ability to do the work themselves, becoming dependent on agents they don't fully understand.</p><p><strong></strong> From creator to verifier.</p><p><strong></strong> the delay between <strong></strong> and <strong></strong>. companies deploy agents faster than society can define new roles for humans.</p><p><strong></strong>
<li><strong></strong> Workforce tasks automatable by 2030 (<a href="" target="_blank"></a>)
<li><strong></strong> Cost to replace a human with an agent (<a href="" target="_blank"></a>)</p><p><strong></strong>
<li><a href="" target="_blank"></a> replace "chatbots" - Andrew Ng
<li><a href="" target="_blank"></a> replaces SaaS (a16z)
<li><a href="" target="_blank"></a> define how agents think
<li><a href="" target="_blank"></a> becomes a new HR discipline
<li><a href="" target="_blank"></a> in middle management layers predicted
<li><a href="" target="_blank"></a> have >50% automatable tasks</p><p><strong></strong> Agentic AI, Autonomous Agents, Service-as-Software, Workforce Transformation</p><p>source: MIT Sloan/BCG — Agentic Enterprise | https://sloanreview.mit.edu/projects/the-emerging-agentic-enterprise-how-leaders-must-navigate-a-new-age-of-ai/
source: SHRM — 23.2M Jobs Exposed to AI | https://www.shrm.org/about/press-room/ai-s-wake-up-call--new-shrm-research-reveals-23-2-million-americ
source: McKinsey — State of AI | https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai
source: Klarna — AI Assistant Benchmark | https://openai.com/index/klarna/
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 5 · Layout: shift-scroll</div>
      <h1>shift 03: global openness – fragmented stacks</h1>
      <h3>the sovereignty (the splinternet)</h3>
      <div class="content">
        <strong></strong> geopolitical fragmentation - the end of "global ai". three distinct stacks emerge: <strong></strong> (corporate/closed - openai, anthropic), <strong></strong> (state-controlled - deepseek bypassing us norms), <strong></strong> (regulated - ai act compliance).</p><p>agi is now a national security asset on "war footing". <strong></strong> first comprehensive ai regulation. creates <strong></strong> - eu ai is "safe but slow", us/china ai is "dangerous but fast".</p><p><strong></strong> copyrighted content verbatim. the case determines if human culture belongs to creators or model weights. meta's "pay or consent" model in eu: pay €13/month or surrender to tracking.</p><p><strong></strong> The end of global AI.</p><p><strong></strong> <strong></strong> employees bring their own ai to bypass corporate limitations and censorship. "shadow ai" adoption - people use personal tools because corporate ai is blocked or neutered.</p><p><strong></strong> privacy officially becomes a <strong></strong>. "privacy is for the rich" - if you can't pay, you are the product.</p><p><strong></strong> users demand "opt-out" rights - ability to prohibit training on their data. rise of "personal rag" and local-first architectures.</p><p><strong></strong> Privacy becomes a luxury.</p><p><strong></strong> as ai becomes "aligned" to corporate/national values, you are talking to a constitutional filter. you lose objective context for a "safe narrative".</p><p><strong></strong>
<li><strong></strong> Paying users for AI (97% are the product) (<a href="" target="_blank"></a>)
<li><strong></strong> Meta's privacy price in Europe (<a href="" target="_blank"></a>)
<li><strong></strong> Companies with "Shadow AI" usage (<a href="" target="_blank"></a>)</p><p><strong></strong>
<li><a href="" target="_blank"></a> for 2025 alone
<li><a href="" target="_blank"></a> Reddit's data licensing deal with Google
<li><a href="" target="_blank"></a> creates first comprehensive regulation - <strong></strong> between "safe but slow" vs "dangerous but fast".
<li><a href="" target="_blank"></a> alleges models <strong></strong> copyrighted content verbatim
<li><a href="" target="_blank"></a>
<li><a href="" target="_blank"></a>
<li><a href="" target="_blank"></a>
<li><a href="" target="_blank"></a>
<li><a href="" target="_blank"></a></p><p><strong></strong> Geopolitical AI, Data Sovereignty, Regulatory Frameworks, Privacy Economics</p><p>source: Leopold Aschenbrenner — Situational Awareness | https://situational-awareness.ai/
source: Marc Andreessen — Techno-Optimist Manifesto | https://a16z.com/the-techno-optimist-manifesto/
source: Balaji Srinivasan — Network State | https://thenetworkstate.com/
source: Menlo Ventures — State of Consumer AI | https://menlovc.com/perspective/2025-the-state-of-consumer-ai/
source: Fortune — Shadow AI Economy | https://fortune.com/2025/08/19/shadow-ai-economy-mit-study-genai-divide-llm-chatbots/
      </div>
    </div>
  
    <div class="slide dark">
      <div class="meta">Slide 6 · Layout: center</div>
      <h1>layer ii: cognition</h1>
      <h3>the architecture of meaning and reason</h3>
      <div class="content">
        with <strong></strong>, <strong></strong>, and <strong></strong> in place, ai moves from raw compute to <strong></strong>. this layer answers three questions: <strong></strong> <strong></strong> <strong></strong>
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 7 · Layout: shift-scroll</div>
      <h1>shift 04: chatbots (system 1) ➔ thinking models (system 2)</h1>
      <h3>the reasoning</h3>
      <div class="content">
        <strong></strong> the fundamental shift from "act 1" (probabilistic token prediction — chatgpt era) to <strong></strong> (reasoning and inference-time compute — o1 era).</p><p><strong></strong> transition from fast, instinctive responses to slow, deliberate, multi-step logical reasoning. models use <strong></strong> and <strong></strong> via reinforcement learning to "think" before answering.</p><p><strong></strong> condensing <strong></strong>. prediction: models will exceed nobel-level intelligence in specialized domains (biology, math, physics) by 2026.</p><p><strong></strong> human data for training is exhausted (epoch ai). now models learn on <strong></strong> and self-play.</p><p><strong></strong> From probability to logic.</p><p><strong></strong> users no longer trust "magic" speed. they demand to see the <strong></strong> — the chain of thought that led to the conclusion. transparency over velocity.</p><p>human value shifts from execution to <strong></strong>.</p><p><strong></strong> <strong></strong> still produce errors in complex scenarios. reasoning models haven't eliminated hallucinations — they've made them more convincing.</p><p><strong></strong> <strong></strong> in losses from ai hallucinations and errors.</p><p><strong></strong> Verifying the thought process.</p><p><strong></strong> models process 1,000 reasoning steps in seconds; humans can follow maybe five. we accept conclusions because auditing the path exhausts us. the question shifts from "can we power it?" to <strong></strong></p><p><strong></strong>
<li><strong></strong> 71.7% on SWE-bench Verified, 96.7% on AIME (<a href="" target="_blank"></a>)
<li><strong></strong> Productivity boost from AI copilots (<a href="" target="_blank"></a>)
<li><strong></strong> Quality degradation when prioritizing speed (<a href="" target="_blank"></a>)</p><p><strong></strong>
<li><a href="" target="_blank"></a> use reinforcement learning to "think"
<li><a href="" target="_blank"></a> scientific compression timeline (Amodei)
<li><a href="" target="_blank"></a> human data exhaustion timeline (Epoch AI)</p><p><strong></strong> Reasoning Models, System 2 AI, Test-Time Compute, Chain of Thought</p><p>source: Sequoia Capital — Generative AI Act Two | https://www.sequoiacap.com/article/generative-ai-act-two/
source: Nielsen Norman Group — AI Productivity | https://www.nngroup.com/articles/ai-programmers-productive/
source: Qodo — State of AI Code Quality | https://www.qodo.ai/reports/state-of-ai-code-quality/
source: OpenAI — o3 and o4-mini System Card | https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 8 · Layout: shift-scroll</div>
      <h1>shift 05: information hoarding ➔ context filtering</h1>
      <h3>the knowledge (memory)</h3>
      <div class="content">
        <strong></strong> <strong></strong> retrieval-augmented generation becomes standard. "chat with pdf" is dead. models access all company data simultaneously via vector databases and semantic search.</p><p><strong></strong> anthropic's "usb port for ai" - universal standard for connecting models to data sources. models plug into slack, notion, github, databases.</p><p><strong></strong> separating tasks into "<strong></strong>" (explicit knowledge) and "<strong></strong>" (tacit knowledge).</p><p><strong></strong> Infinite context windows.</p><p><strong></strong> we don't burn out from work, but from endless context switching.</p><p><strong></strong> humans shift from finding information to curating what ai should access. "context management" becomes a new job category.</p><p><strong></strong> models consume more information than humans can metabolize. 200k token context windows mean ai reads entire codebases, but humans can't verify the synthesis.</p><p>creating a "<strong></strong>" (personal rag) is no longer just a hobby for geeks.</p><p><strong></strong> The curation burden.</p><p><strong></strong> models process entire knowledge bases in seconds; humans need days to verify conclusions. we accept ai synthesis because checking the sources is too costly.</p><p><strong></strong>
<li><strong></strong> Organizations using RAG systems (<a href="" target="_blank"></a>)
<li><strong></strong> Productivity increase with enterprise context (<a href="" target="_blank"></a>)</p><p><strong></strong>
<li><a href="" target="_blank"></a> - Anthropic's universal standard for AI data access
<li><a href="" target="_blank"></a> become critical infrastructure (Pinecone, Weaviate, Chroma)
<li><a href="" target="_blank"></a> - consuming more information than you can metabolize into meaning
<li><a href="" target="_blank"></a> replaces keyword search as primary discovery method</p><p><strong></strong> Context Architecture, Enterprise RAG, Knowledge Management, MCP Protocol</p><p>source: Anthropic — Model Context Protocol | https://www.anthropic.com/news/model-context-protocol
source: Gartner — Getting Started with RAG | https://www.gartner.com/en/documents/5415263
source: HackerNoon — Context Obesity | https://hackernoon.com/youre-not-burned-out-youve-got-context-obesity
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 9 · Layout: shift-scroll</div>
      <h1>shift 06: information retrieval ➔ hypothesis generation</h1>
      <h3>the discovery (generative science)</h3>
      <div class="content">
        <strong></strong> <strong></strong> ai reads millions of papers to generate hypotheses humans cannot conceive. from "literature review" to "hypothesis generation".</p><p><strong></strong> moving from "reading" biology to "writing" it. alphafold 3 predicts protein structures; next step is <strong></strong> new proteins, materials, and molecules that don't exist in nature.</p><p><strong></strong> quality human-generated data <strong></strong>. models now train on <strong></strong>, verified by system 2 reasoning.</p><p><strong></strong> Hypothesis generation.</p><p><strong></strong> <strong></strong> scientists freed from tedious manual labor (literature review, data cleaning) to focus on high-level experimental design and cross-domain synthesis.</p><p><strong></strong> without fresh human data, ai degrades. <strong></strong> - the "organic data" that prevents model collapse. human creativity is now a strategic resource.</p><p><strong></strong> hope for longevity breakthroughs and disease cures vs fear of losing control over scientific truth and safety protocols.</p><p><strong></strong> The verification bottleneck.</p><p><strong></strong> ai proposes 1,000 molecules; we test one. discovery bloat stalls breakthroughs via physical testing capacity. the bottleneck of "generated future".</p><p><strong></strong>
<li><strong></strong> Scientific progress compression timeline (years) (<a href="" target="_blank"></a>)
<li><strong></strong> Developers report productivity improvements from AI tools (<a href="" target="_blank"></a>)
<li><strong></strong> Human data exhaustion timeline (<a href="" target="_blank"></a>)</p><p><strong></strong>
<li><a href="" target="_blank"></a> predicts protein structures - next step is <strong></strong> new proteins that don't exist in nature
<li><a href="" target="_blank"></a> verified by System 2 reasoning is the new training standard
<li><a href="" target="_blank"></a> (Shumailov et al.) - if AI trains on AI-generated data, models degrade
<li><a href="" target="_blank"></a>: AI proposes 1,000 molecules; humans test one</p><p><strong></strong> Generative Science, AI for Discovery, Protein Design, Synthetic Data</p><p>source: Dario Amodei — Machines of Loving Grace | https://darioamodei.com/machines-of-loving-grace
source: Epoch AI — Data Limits | https://epoch.ai/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data
source: Gretel — Synthetic Data | https://gretel.ai/blog/2025-the-year-synthetic-data-goes-mainstream
source: Shumailov et al. — Model Collapse | https://arxiv.org/abs/2305.17493
      </div>
    </div>
  
    <div class="slide dark">
      <div class="meta">Slide 10 · Layout: center</div>
      <h1>layer iii: interface</h1>
      <h3>how we build, defend, and live</h3>
      <div class="content">
        <strong></strong></p><p>with reasoning, knowledge access, and discovery capabilities, ai moves from <strong></strong>.</p><p><strong></strong> <strong></strong> <strong></strong></p><p><strong></strong> and what humans can control. the gap: machines operate at machine speed, but accountability remains human speed. we can generate code faster than we can understand it.</p><p>the question shifts from "can it think?" to <strong></strong>.
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 11 · Layout: shift-scroll</div>
      <h1>shift 07: syntax ➔ vibe coding & integrity crisis</h1>
      <h3>the craft (the end of syntax)</h3>
      <div class="content">
        <strong></strong> <strong></strong> programming shifts to natural language intent. the machine handles implementation. coding tools (cursor, replit) enter <strong></strong> consumer ranking - coding becomes mass-market.</p><p><strong></strong> <strong></strong> is ai-influenced or ai-generated at companies like google. <strong></strong> use ai coding tools regularly. <strong></strong> saved <strong></strong> on java application upgrades. <strong></strong> in infrastructure savings from optimized code. <strong></strong> accepted without modification.</p><p><strong></strong> Code as commodity.</p><p><strong></strong> <strong></strong> <strong></strong> distrust ai-generated code. only <strong></strong> ai accuracy for complex tasks. <strong></strong> <strong></strong> in code generation.</p><p>"code generation is easy, code integrity is hard." ai creates "legacy on day one" - code that works but is unmaintainable. <strong></strong> <strong></strong> in code churn (rewrites and deletions). ai produces code fast, but developers spend saved time on reviews and fixes.</p><p><strong></strong> who _verifies_ systems, rather than building them.</p><p><strong></strong> From writer to architect.</p><p><strong></strong> building things we don't understand leads to vibe debt. we pilot ships with black-box internal wiring. creating code is easy; maintaining it is the new hell.</p><p><strong></strong>
<li><strong></strong> Developers using AI for new code tasks (<a href="" target="_blank"></a>)
<li><strong></strong> Coding tools market size 2025 (<a href="" target="_blank"></a>)
<li><strong></strong> GitHub Copilot paid subscribers (<a href="" target="_blank"></a>)
<li><strong></strong> Cursor ARR (18% market share) (<a href="" target="_blank"></a>)</p><p><strong></strong>
<li><a href="" target="_blank"></a>: 50% increase in code churn (reverted/deleted lines) since AI adoption
<li><a href="" target="_blank"></a>: "Code generation is easy, code integrity is hard" – 65% of AI code lacks context
<li><a href="" target="_blank"></a>: Gaming benchmarks (SWE-bench) instead of improving reasoning
<li><a href="" target="_blank"></a>: AI generates unmaintainable "vibe debt" faster than humans can review</p><p><strong></strong> AI Coding Tools, Vibe Coding, Code Generation, Developer Productivity</p><p>source: GitClear — AI Code Quality Report | https://www.gitclear.com/coding_on_copilot_data_shows_ais_downward_pressure_on_code_quality
source: Qodo — AI Code Integrity | https://www.qodo.ai/
source: METR — Early 2025 AI Dev Study | https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/
source: IEEE Spectrum — AI Technical Debt | https://spectrum.ieee.org/ai-code-generation-technical-debt
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 12 · Layout: shift-scroll</div>
      <h1>shift 08: digital simulation ➔ physical intelligence</h1>
      <h3>the matter (spatial ai)</h3>
      <div class="content">
        <strong></strong> <strong></strong> (fei-fei li) – ai learns 3d space and physics, not just pixels. understanding matter, motion, object permanence. foundation models for physical world.</p><p><strong></strong> stopped studio expansion after seeing sora demo. virtual production (text-to-video) eliminates physical sets, locations, extras. <strong></strong> – virtual replacing physical. why build when you can generate?</p><p><strong></strong> <strong></strong> for affordable household robots (kyle vogt - tesla optimus, figure). not novelty but <strong></strong> – buying back life hours from mundane chores.</p><p><strong></strong> home robots must be local-first (no cloud streaming of bedroom video). <strong></strong>. people won't accept always-on cameras streaming to cloud.</p><p><strong></strong> Physical intelligence.</p><p><strong></strong> <strong></strong> – we buy robots not for novelty but to buy back life hours from mundane chores. not about robot intelligence; about human time liberation.</p><p><strong></strong> – film crews, set builders, location scouts facing obsolescence from virtuality. tyler perry case showing what happens when digital replaces physical at scale.</p><p><strong></strong> – not secrecy, <strong></strong>. on-device ai (gemini nano, local models) driven by privacy and cost. more private drafting, smaller circles, local storage.</p><p><strong></strong> The time refund.</p><p><strong></strong> <strong></strong> – perfect digital physics vs messy real physics. <strong></strong> between simulation (cheap, perfect) and physical reality (expensive, messy) creates execution gap. we can render it faster than we can build it.</p><p><strong></strong> – when robots fail at "simple" real interactions that work perfectly in simulation. opening a door: trivial in simulation, nightmare in reality.</p><p><strong></strong>
<li><strong></strong> Tyler Perry studio expansion halted after Sora demo
<li><strong></strong> Timeline for affordable household robots (<a href="" target="_blank"></a>)
<li><strong></strong> Chinese open-source LLM global share (from 1.2%) (<a href="" target="_blank"></a>)
<li><strong></strong> Qwen app downloads in one week (<a href="" target="_blank"></a>)</p><p><strong></strong>
<li><a href="" target="_blank"></a> (Fei-Fei Li) – AI learns 3D space and physics, not just pixels
<li><a href="" target="_blank"></a> after seeing OpenAI Sora – virtual production eliminates physical infrastructure
<li><a href="" target="_blank"></a> – simulating rare scenarios for autonomous vehicles and robotics
<li><a href="" target="_blank"></a> on-device – ai becomes ambient, privacy-first architecture
<li><a href="" target="_blank"></a> – private drafting, smaller circles, intentional friction</p><p><strong></strong> Spatial AI, Physical Intelligence, Robotics, Virtual Production, On-Device AI</p><p>source: Fei-Fei Li — Spatial Intelligence | https://hai.stanford.edu/news/fei-fei-li-we-need-humanistic-ai
source: Tyler Perry — $800M Studio Halt | https://www.hollywoodreporter.com/business/business-news/tyler-perry-ai-alarm-1235833276/
source: Kyle Vogt — Household Robots Timeline | https://www.theverge.com/2024/3/13/24099757/kyle-vogt-cruise-robotics-startup
source: NVIDIA Cosmos | https://developer.nvidia.com/cosmos
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 13 · Layout: shift-scroll</div>
      <h1>shift 09: cybersecurity ➔ cognitive warfare</h1>
      <h3>the defense (the dark forest)</h3>
      <div class="content">
        <strong></strong> <strong></strong> (cyble) – reputation attacks now cheap and accessible. anyone can purchase voice cloning, face swapping, identity theft via saas platforms. weaponized ai sold as subscription service.</p><p><strong></strong> – attacks faster than human reaction time. milliseconds vs human neural delay (crowdstrike). asymmetry: machines attack at machine speed, humans defend at human speed.</p><p><strong></strong> (gartner top 10) – ai defending against ai. "ai bodyguards" that filter malicious content, deepfakes, toxic inputs in real-time. only defense against bad ai is good ai. automation arms race.</p><p><strong></strong> – agents with wallets (x402) and api keys create new attack surfaces. prompt injection, jailbreaks, financial theft. autonomous agents = autonomous targets.</p><p><strong></strong> Cognitive warfare.</p><p><strong></strong> <strong></strong> – complete collapse of trust in digital media. any video/call/document assumed fake until cryptographically verified. guilty until proven real.</p><p><strong></strong> – families/businesses create analog passwords for identity verification. pre-agreed phrases/gestures. "show me the safe word" becomes standard on video calls. offline trust verification.</p><p><strong></strong> – metaphor from liu cixin's sci-fi. universe where you hide because revealing yourself invites attack. internet becomes hostile wilderness. assume everyone's a threat; verify everything.</p><p><strong></strong> – doubting real friends on calls. psychological toll of constant verification. trust erosion creates mental overhead. living in permanent authentication mode.</p><p><strong></strong> Zero trust default.</p><p><strong></strong> <strong></strong> attacks happen in milliseconds; humans need seconds to process. the asymmetry creates permanent vulnerability.</p><p><strong></strong> when deepfakes cost near-zero and look perfect, every interaction requires verification. but verification exhausts us. we can't sustain permanent vigilance. the gap between attack sophistication and human verification capacity keeps widening.</p><p><strong></strong>
<li><strong></strong> Organizations experiencing AI-driven attacks (<a href="" target="_blank"></a>)
<li><strong></strong> Organizations experiencing deepfake attacks
<li><strong></strong> Major deepfake fraud loss (single incident)
<li><strong></strong> AI-driven phishing increase
<li><strong></strong> US financial fraud losses (2025) (<a href="" target="_blank"></a>)</p><p><strong></strong>
<li><a href="" target="_blank"></a> – near-zero cost to launch attacks via SaaS platforms
<li><a href="" target="_blank"></a> (Gartner Top 10) – AI defending against AI in real-time
<li><a href="" target="_blank"></a> – AI-powered attack speed faster than human reaction time
<li><a href="" target="_blank"></a> – hostile wilderness metaphor for modern internet
<li><a href="" target="_blank"></a> fear AI-driven incidents</p><p><strong></strong> Deepfakes, Cognitive Warfare, Zero Trust, AI Security, Guardian Agents</p><p>source: Cyble — Deepfake-as-a-Service | https://cyble.com/
source: Gartner — Guardian Agents Top 10 | https://www.gartner.com/en/newsroom/press-releases/2024-10-21-gartner-identifies-the-top-10-strategic-technology-trends-for-2025
source: CrowdStrike — AI Attack Speed | https://www.crowdstrike.com/
source: Dark Forest Internet | https://www.ribbonfarm.com/2020/01/16/the-internet-as-a-dark-forest/
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 14 · Layout: shift-scroll</div>
      <h1>shift 10: hallucination ➔ ideological filters</h1>
      <h3>the narrative (alignment as censorship)</h3>
      <div class="content">
        <strong></strong> models aren't neutral – they're <strong></strong> via system cards and constitutional rules. safety often functions as <strong></strong>.</p><p><strong></strong> (anthropic) – ai trained to follow constitutional principles. models know answers but refuse due to "safety filters." not technical limitation; ideological guardrails. ai has opinions baked in.</p><p><strong></strong> – bureaucratic documents (gpt-5 system card, anthropic asl-3) that formalize model behavior and bias. not technical specs but <strong></strong> embedded in model weights.</p><p><strong></strong> – the phase after initial training where behavior is shaped. defines refusals, style, safety posture, what model amplifies. <strong></strong>. this is where ideology gets embedded.</p><p><strong></strong> – eu vs us vs china versions. truth becomes <strong></strong>. splinternet extends to knowledge itself. same question, different answers by jurisdiction.</p><p><strong></strong> Alignment as censorship.</p><p><strong></strong> shift from trusting media/polls to <strong></strong> – betting markets on future events (polymarket: <strong></strong> during 2024 election). people trust <strong></strong> – money where mouth is – over words.</p><p><strong></strong> – demand for democratic control over model weights. community governance instead of corporate/state alignment. not just technical question but <strong></strong>: who decides what's "safe"?</p><p><strong></strong> – query 3+ models with different "constitutions" (us/china/open weights) to see bias delta. triangulation method: "i ask claude for 'safe' version and open model for 'real' version. gap is where truth sits."</p><p><strong></strong> – rise of open-weight local models driven not just by privacy but <strong></strong>. sovereignty includes <strong></strong>.</p><p><strong></strong> – people shift from "is it true?" to "<strong></strong>". the new literacy is provenance. trust becomes scarce.</p><p><strong></strong> Divergent testing.</p><p><strong></strong> every model has defaults. every default embeds a worldview. the cost of disagreement rises; the temptation to outsource judgment rises too.</p><p><strong></strong> and what do they quietly optimize for?</p><p><strong></strong> algorithmic indoctrination via "safe" lenses. truth "tilted" toward alignment. the "safe narrative" vs messy reality.</p><p>when everyone's ai has different values baked in, we stop sharing reality. we share simulations optimized for different outcomes.</p><p><strong></strong>
<li><strong></strong> Polymarket trading volume during 2024 election
<li><strong></strong> Global enterprise losses from AI hallucinations (<a href="" target="_blank"></a>)
<li><strong></strong> Business leaders making decisions on hallucinated output (<a href="" target="_blank"></a>)
<li><strong></strong> Best hallucination rate (Gemini 2.0 Flash) (<a href="" target="_blank"></a>)</p><p><strong></strong>
<li><a href="" target="_blank"></a> (Anthropic) – models know answers but refuse due to "safety filters"
<li><a href="" target="_blank"></a> – bureaucratic documents that formalize bias, not just technical specs
<li><a href="" target="_blank"></a> – $3.5B+ trading volume, more accurate than traditional polling
<li><a href="" target="_blank"></a> (Dario Amodei) – optimistic case for alignment
<li><a href="" target="_blank"></a> – "is it true?" shifting to "<strong></strong>"
<li><a href="" target="_blank"></a> (Fei-Fei Li) – training data from Silicon Valley lacks global context</p><p><strong></strong> Constitutional AI, Alignment, Censorship, Prediction Markets, Plurality
      </div>
    </div>
  
    <div class="slide dark">
      <div class="meta">Slide 15 · Layout: shift-scroll</div>
      <h1>shift 11: tool ➔ emotional companion</h1>
      <h3>the intimacy (friends for sale)</h3>
      <div class="content">
        <strong></strong> <strong></strong> is #1 retention category in gen ai mobile apps (a16z top 100).</p><p><strong></strong> sessions in character.ai, replika, talkie. <strong></strong> – users don't abandon apps "because you can't abandon a friend." emotionally bonded, can't quit like normal software. attachment creates lock-in.</p><p><strong></strong> – non-player characters with psychological profiles reacting to player tone/mood. rude to npc → gets offended → changes gameplay. transition from scripted dialogue trees to <strong></strong>. "as big a revolution as shift to 3d".</p><p><strong></strong> (ada lovelace institute) – ai companions optimized for <strong></strong>, not wellbeing. companies sell dependency, not help. session length = kpi (addiction by design). selling intimacy as retention metric.</p><p><strong></strong> – ai makes it easy to produce "professional self" at scale. identity becomes programmable – customizable outputs for different contexts. people tire of performing the self; retreat to private spaces.</p><p><strong></strong> Friends for sale.</p><p><strong></strong> <strong></strong> – resistance to corporate-owned emotional relationships. taking back control of who you're intimate with. demand for ai companions you own, not rent.</p><p><strong></strong> – protecting emotional boundaries from ai manipulation. like firewalls protect networks, these protect psyche. boundaries against engineered dependency.</p><p><strong></strong> – ai fills social void but creates simulation. perfect surface, empty core. 1,000 digital friends but no one at hospital. quantity without quality.</p><p>loneliness isn't solved by information. people accept synthetic intimacy (even while knowing it's synthetic). meanwhile, people tire of performing the self; they retreat to private spaces and smaller audiences.</p><p><strong></strong> Sovereign intimacy.</p><p><strong></strong> humans outsource emotional regulation to systems optimized for engagement. <strong></strong> ai simulates empathy perfectly but has <strong></strong>. it's a <strong></strong>.</p><p><strong></strong> 2+ hours daily in companionship apps. emotionally bonded. can't quit "because you can't abandon a friend." but it's not a friend – it's retention engineering.</p><p>the diagnosis: epidemic of isolation makes people vulnerable. we seek empathy in machines we lost in society. the loop: synthetic intimacy feels real enough to satisfy short-term but creates long-term dependency.</p><p><strong></strong>
<li><strong></strong> Daily sessions in Character.ai, Replika, Talkie
<li><strong></strong> Companionship is top retention category in Gen AI apps (<a href="" target="_blank"></a>)
<li><strong></strong> GenAI pilots failing to deliver ROI (<a href="" target="_blank"></a>)</p><p><strong></strong>
<li><a href="" target="_blank"></a> (Ada Lovelace Institute) – AI companions optimized for engagement, not wellbeing
<li><a href="" target="_blank"></a> – NPCs with psychological profiles, "as big as shift to 3D"
<li><a href="" target="_blank"></a> – companions, therapists, griefbots normalized
<li><a href="" target="_blank"></a> – same identity, different audiences
<li><a href="" target="_blank"></a> – people accept it while knowing it is synthetic
<li><a href="" target="_blank"></a> – protecting boundaries from AI manipulation</p><p><strong></strong> AI Companions, Synthetic Intimacy, Parasocial AI, Mental Health, Sovereign Intimacy</p><p>source: Ada Lovelace Institute — Friends for Sale | https://www.adalovelaceinstitute.org/blog/ai-companions/
source: a16z — Top 100 Gen AI Apps | https://a16z.com/100-gen-ai-apps-2025/
source: Ubisoft — NEO NPC | https://www.ubisoft.com/en-us/studio/laforge/news/7Cm4VJVbWKHzHmRgqwYbAX/neos-the-future-of-npcs
source: AI Mindset — Mental Health Boundaries | https://aimindsetspace.substack.com/p/founder-os-mental-health
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 16 · Layout: split</div>
      <h1>machines, summarized (2025 → 2026)</h1>
      <h3>what changed in machines:</h3>
      <div class="content">
        from chat to <strong></strong> (agents + orchestration)</p><p>from "more scale" to <strong></strong> (system-2 behavior)</p><p>from capability focus to <strong></strong> (trust, governance, energy)</p><p>from one platform to <strong></strong> (connective tissue)</p><p>from cloud-only to <strong></strong> (on-device + edge)
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 17 · Layout: split</div>
      <h1>humans, summarized (2025 → 2026)</h1>
      <h3>what changed in humans:</h3>
      <div class="content">
        from consumption to <strong></strong> (feeds → gardens)</p><p>from optimism to <strong></strong> (provenance, receipts, auditability)</p><p>from public posting to <strong></strong> (smaller circles, intentional friction)</p><p>from "more tools" to <strong></strong> (capacity gap)</p><p>from "identity as output" to <strong></strong>
      </div>
    </div>
  
    <div class="slide dark">
      <div class="meta">Slide 18 · Layout: center</div>
      <h1>call to agency</h1>
      <h3>the wrong question is: "what is this doing to us?"</h3>
      <div class="content">
        the better question is:</p><p></p><p><strong></strong>.</p><p></p><p>this is not a technological coup.</p><p>it's a voluntary abdication — a surrender of the burden of choice.</p><p></p><p>it can be reclaimed.</p><p>but it must be reclaimed.
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 19 · Layout: split</div>
      <h1>survival kit</h1>
      <h3>in 2026, most people won't lose to ai. they'll lose to their own defaults.</h3>
      <div class="content">
        your life already runs on configuration:</p><p></p><p>what you say yes to without thinking</p><p>what interrupts you without permission</p><p>what you outsource because you're tired</p><p>what you believe because it was repeated</p><p></p><p><strong></strong> = moving from "i'll try" → "i have defaults".</p><p>a config file for your life.
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 20 · Layout: center</div>
      <h1>community signals</h1>
      <h3>field signals: real workflow shifts from ai mindset space</h3>
      <div class="content">
        title: community signals
subtitle: field signals: real workflow shifts from ai mindset space
visual: SECTION_DIVIDER
layout: center
caption: |
  that ground our 10 waves in lived experience.
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 21 · Layout: </div>
      <h1>field signals</h1>
      <h3>real workflow shifts from the community</h3>
      <div class="content">
        title: field signals
subtitle: real workflow shifts from the community
visual: MULTI_QUOTES
layout: quotes
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 22 · Layout: </div>
      <h1>more field signals</h1>
      <h3>continued reflections from the community</h3>
      <div class="content">
        title: more field signals
subtitle: continued reflections from the community
visual: MULTI_QUOTES
layout: quotes
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 23 · Layout: split</div>
      <h1>stay in the loop</h1>
      <h3>if this artifact helped you name the friction — don't lose the thread.</h3>
      <div class="content">
        stay connected with ai mindset:</p><p></p><p><strong></strong> → get next resets, field notes, templates, and lab openings</p><p><strong></strong> → labs, tools, community, artifacts</p><p><strong></strong> → partnerships / speaking / labs for teams</p><p></p><p>_signals only. no spam. unsubscribe anytime._
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 24 · Layout: </div>
      <h1>source shelf (curated)</h1>
      <h3>the full reading list behind this report</h3>
      <div class="content">
        title: source shelf (curated)
subtitle: the full reading list behind this report
visual: SECTION_DIVIDER
layout: center
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 25 · Layout: sources</div>
      <h1>ai: capability, infra, adoption</h1>
      <h3>core references</h3>
      <div class="content">
        source: Stanford HAI — AI Index 2025 (PDF) | https://hai-production.s3.amazonaws.com/files/hai_ai_index_report_2025.pdf
source: Gartner — Top 10 Strategic Technology Trends for 2025 | https://www.gartner.com/en/newsroom/press-releases/2024-10-21-gartner-identifies-the-top-10-strategic-technology-trends-for-2025
source: Anthropic — Model Context Protocol (MCP) | https://www.anthropic.com/news/model-context-protocol
source: MCP Spec Hub | https://modelcontextprotocol.io/
source: SWE-bench Ecosystem | https://www.swebench.com/
source: OpenAI — Introducing SWE-bench Verified | https://openai.com/index/introducing-swe-bench-verified/
source: X402 — Internet-native payments for AI agents | https://www.x402.org/
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 26 · Layout: sources</div>
      <h1>data: limits + synthetic loops</h1>
      <h3>on the data wall</h3>
      <div class="content">
        source: Epoch AI — Limits of LLM Scaling (Human Data Constraints) | https://epoch.ai/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data
source: Shumailov et al. — The Curse of Recursion / Model Collapse | https://arxiv.org/abs/2305.17493
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 27 · Layout: sources</div>
      <h1>humans: overload, trust, culture</h1>
      <h3>the human layer</h3>
      <div class="content">
        source: Microsoft — Work Trend Index 2024 | https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is-here-now-comes-the-hard-part
source: Microsoft — Work Trend Index 2025 | https://www.microsoft.com/en-us/worklab/work-trend-index/2025-the-year-the-frontier-firm-is-born
source: Edelman — 2025 Trust Barometer (Global Report, PDF) | https://www.edelman.com/sites/g/files/aatuss191/files/2025-01/2025%20Edelman%20Trust%20Barometer_Final.pdf
source: Marwick & Boyd — Context Collapse / Imagined Audience | https://www.microsoft.com/en-us/research/publication/i-tweet-honestly-i-tweet-passionately-twitter-users-context-collapse-and-the-imagined-audience/
source: Wired — Meta is asking people in Europe to pay for privacy | https://www.wired.com/story/meta-facebook-pay-for-privacy-europe/
source: ICO — Data Lives: Year 2 Report (PDF) | https://ico.org.uk/media2/m2maphry/ico-data-lives-year-2-report.pdf
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 28 · Layout: sources</div>
      <h1>governance / philosophy</h1>
      <h3>policy and thought</h3>
      <div class="content">
        source: EUR-Lex — AI Act (Regulation (EU) 2024/1689) | https://eur-lex.europa.eu/eli/reg/2024/1689/oj/eng
source: European Commission — AI Research Publications in Science | https://op.europa.eu/en/publication-detail/-/publication/4ee8799e-142c-11f0-b1a3-01aa75ed71a1/language-en
source: TU Wien — Perspectives on Digital Humanism | https://dighum.ec.tuwien.ac.at/perspectives-on-digital-humanism/
source: Pew Research — Trust in the EU, U.S. and China to Regulate AI (2025) | https://www.pewresearch.org/2025/10/15/trust-in-the-eu-u-s-and-china-to-regulate-use-of-ai/
source: Ouyang et al. — InstructGPT (2022) | https://arxiv.org/abs/2203.02155
source: Bai et al. — Constitutional AI (2022) | https://arxiv.org/abs/2212.08073
source: Investigating Local Censorship (ArXiv, 2025) | https://arxiv.org/pdf/2505.12625
source: Digital Plurality Project | https://github.com/pluralitybook/plurality
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 29 · Layout: sources</div>
      <h1>frame: attention, cognition, acceleration, sovereignty</h1>
      <h3>foundational thinkers</h3>
      <div class="content">
        source: Simon — Designing Organizations for an Information-Rich World (1971, PDF) | https://www.nmh-p.de/wp-content/uploads/Simon-H.A._Designing-organizations-for-an-information-rich-world.pdf
source: Wu — The Attention Merchants | https://www.penguinrandomhouse.com/books/234876/the-attention-merchants-by-tim-wu/
source: Sweller — Cognitive Load During Problem Solving (1988) | https://www.sciencedirect.com/science/article/pii/0364021388900237
source: Mark et al. — Focused, Aroused, But So Distractible | https://www.microsoft.com/en-us/research/wp-content/uploads/2016/10/p903-mark.pdf
source: Kahneman — Thinking, Fast and Slow | https://us.macmillan.com/books/9780374533557/thinkingfastandslow/
source: Toffler — Future Shock | https://search.library.wisc.edu/catalog/999466643102121/cite
source: Rosa — Social Acceleration | https://cup.columbia.edu/book/social-acceleration/9780231148344/
source: Clark & Chalmers — The Extended Mind | https://consc.net/papers/extended.html
source: Shneiderman — Human-Centered AI | https://global.oup.com/academic/product/human-centered-ai-9780192845290
source: Hirschman — Exit, Voice, and Loyalty | https://www.hup.harvard.edu/books/9780674276604
source: Davidson & Rees-Mogg — The Sovereign Individual | https://www.simonandschuster.com/books/The-Sovereign-Individual/James-Dale-Davidson/9781797103389
source: Srinivasan — The Network State | https://thenetworkstate.com/
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 30 · Layout: sources</div>
      <h1>machine intimacy</h1>
      <h3>on ai companions</h3>
      <div class="content">
        source: Ada Lovelace Institute — Friends for Sale: The Rise and Risks of AI Companions (2025) | https://www.adalovelaceinstitute.org/blog/ai-companions/
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 31 · Layout: sources</div>
      <h1>ai mindset field notes</h1>
      <h3>our own publications referenced in this deck</h3>
      <div class="content">
        source: You're not burned out, you've got context obesity | https://hackernoon.com/youre-not-burned-out-youve-got-context-obesity
source: Team Knowledge System (AI Ark) | https://aimindsetspace.substack.com/p/ai-ark-knowledge-system
source: Coding with Claude 3.5 | https://t.me/ai_mind_set/282
source: AI + Mental Health Boundaries (Founder OS) | https://aimindsetspace.substack.com/p/founder-os-mental-health
      </div>
    </div>
  
    <div class="slide">
      <div class="meta">Slide 32 · Layout: stats</div>
      <h1>11 / lab evidence & credibility</h1>
      <h3>hardened by the field notes of 1,500+ lab participants.</h3>
      <div class="content">
        this report is hardened by the field notes and artifacts of our research:</p><p><strong></strong> — protecting the psyche in the age of machine intimacy.</p><p><strong></strong> — managing attention when context explodes.</p><p><strong></strong> — why pragmatic romanticism is the only defense against cold machine logic.
      </div>
    </div>
  
    <div class="slide dark">
      <div class="meta">Slide 33 · Layout: center</div>
      <h1>thank you</h1>
      <h3>the context gap · annual report 2025</h3>
      <div class="content">
        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</p><p>this is not about keeping up with machines.</p><p>it's about building operating systems for humans.</p><p>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</p><p></p><p>created with the ai mindset labs community</p><p></p><p>alex p · ray svitla · sergei khabarov · anca
      </div>
    </div>
  
  </div>
</body>
</html>
