# AIM Annual Report 2025 - The Context Gap
## Layers & Shifts - Complete Archive

Export Date: 2026-01-16

---

## LAYER I: FOUNDATION
**Physics, Economics, and Power**

The base. Energy infrastructure, agentic labor, data sovereignty.

**The constraint:** Can we power it? Can we afford it? Who controls it?

---

### SHIFT 01: Chip Supply ➔ Power Supply
**The Energy Wall**

**Machine:** **The energy wall:** AI demand for data center power projected to grow **160% by 2030**. Demand for compute is growing faster than power grid capacity. The physical grid cannot be built fast enough to support AI expansion. **Intelligence/watt:** The focus shifts from raw compute to "inference efficiency" as the critical metric. More compute doesn't equal more value if it can't be powered. Data centers are reopening coal plants and demanding nuclear reactors.

**Machine Summary:** The energy wall.

**Human:** **Guilt computing:** Users face the reality that complex reasoning has a physical toll — every AI query consumes water and generates CO2. The disconnect between "green AI" corporate promises and "greed AI" reality.

**Human Summary:** Guilt computing.

**Gap:** The disconnect between infinite "digital ideas" and hard "physical matter". While we imagine a billion agents, we cannot power them. The gap between business desire to deploy AI everywhere and the planet's physical inability to support it.

**Key Stats:**
- **160%:** AI energy demand surge by 2030 ([IEA](https://www.iea.org/reports/electricity-2024) / [Goldman Sachs](https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand))
- **40x:** Gap: $500B infrastructure vs $12B consumer spend ([Menlo Ventures](https://menlovc.com/perspective/2025-the-state-of-consumer-ai/) / [Goldman Sachs](https://www.goldmansachs.com/insights/articles/why-ai-companies-may-invest-more-than-500-billion-in-2026))
- **$7T:** Total AI infrastructure requirement ([McKinsey](https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/the-cost-of-compute-a-7-trillion-dollar-race-to-scale-data-centers) / Sam Altman)

**Research:**
- [The physical grid **cannot be built fast enough** to support AI expansion](https://itbrief.news/story/when-the-grid-becomes-the-bottleneck-the-real-threat-to-ai-deployment)
- Focus shifts from raw compute (FLOPs) to [**"Intelligence per Watt"**](https://snorkel.ai/blog/intelligence-per-watt-a-new-metric-for-ais-future/) as critical metric
- ["A painful power crunch that could constrain AI's growth likely lies ahead"](https://www.goldmansachs.com/intelligence/pages/gen-ai-too-much-spend-too-little-benefit.html) — Brian Janous
- Tech giants reviving [**decommissioned nuclear reactors**](https://www.reuters.com/markets/deals/constellation-inks-power-supply-deal-with-microsoft-2024-09-20/) (Three Mile Island for Microsoft) and obsolete fossil fuel plants

**Tags:** Energy Infrastructure, Nuclear Power, Data Centers, Cloud Computing

---

### SHIFT 02: Assistant ➔ Autonomous Coworker
**The Displacement**

**Machine:** **The agentic enterprise:** Transition from "assistant" to "autonomous coworker". Agents receive wallets (x402 protocol), tools (MCP), and "HR for AI".

**Service-as-software:** SaaS model shifts to agents that execute complete workflows. From selling "software licenses" to "executed outcomes".

**The Klarna benchmark:** One AI assistant replaced 700 full-time agents, slashed resolution time (11m → 2m), drove $40M profit, and achieved 25% fewer repeat inquiries than humans.

**Machine Summary:** The shift from chat to delegation.

**Human:** **Identity crisis:** "If an agent can do my job, who am I?". The psychological toll of moving from "creator" to "manager of agents".

**Managerial drift:** Humans lose the ability to do the work themselves, becoming dependent on agents they don't fully understand.

**Human Summary:** From creator to verifier.

**Gap:** The delay between **technological replacement** and **social adaptation**. Companies deploy agents faster than society can define new roles for humans.

**Key Stats:**
- **47%:** Workforce tasks automatable by 2030 ([McKinsey](https://www.mckinsey.com/mgi/our-research/generative-ai-and-the-future-of-work-in-america))
- **$46k:** Cost to replace a human with an agent ([Ark Invest](https://ark-invest.com/big-ideas-2025/))

**Research:**
- [**Agentic workflows**](https://www.deeplearning.ai/the-batch/issue-242/) replace "chatbots" - Andrew Ng
- [**Service-as-Software**](https://a16z.com/service-as-software/) replaces SaaS (a16z)
- [**Cognitive architectures**](https://blog.langchain.dev/cognitive-architectures/) define how agents think
- [**Hiring for AI**](https://www.linkedin.com/pulse/hiring-ai-new-hr-frontier-josh-bersin/) becomes a new HR discipline
- [**45% reduction**](https://www.axios.com/2025/07/08/ai-middle-managers-flattening-layoffs) in middle management layers predicted
- [**32% of IT jobs**](https://www.oxfordmartin.ox.ac.uk/blog/automation-and-the-future-of-work-understanding-the-numbers) have >50% automatable tasks

**Tags:** Agentic AI, Autonomous Agents, Service-as-Software, Workforce Transformation

---

### SHIFT 03: Global Openness ➔ Fragmented Stacks
**The Sovereignty (The Splinternet)**

**Machine:** Geopolitical fragmentation - the end of "global AI". Three distinct stacks emerge: **US AI** (corporate/closed - OpenAI, Anthropic), **China AI** (state-controlled - DeepSeek bypassing US norms), **EU AI** (regulated - AI Act compliance).

AGI is now a national security asset on "war footing". **EU AI Act:** First comprehensive AI regulation. Creates **regulatory gap** - EU AI is "safe but slow", US/China AI is "dangerous but fast".

**The copyright war - NYT lawsuit alleges models memorize and regurgitate** copyrighted content verbatim. The case determines if human culture belongs to creators or model weights. Meta's "pay or consent" model in EU: pay €13/month or surrender to tracking.

**Machine Summary:** The end of global AI.

**Human:** **The guerrilla stack:** Employees bring their own AI to bypass corporate limitations and censorship. "Shadow AI" adoption - people use personal tools because corporate AI is blocked or neutered.

**Privacy inequality:** Privacy officially becomes a **luxury good**. "Privacy is for the rich" - if you can't pay, you are the product.

**Data sovereignty movement:** Users demand "opt-out" rights - ability to prohibit training on their data. Rise of "personal RAG" and local-first architectures.

**Human Summary:** Privacy becomes a luxury.

**Gap:** As AI becomes "aligned" to corporate/national values, you are talking to a constitutional filter. You lose objective context for a "safe narrative".

**Key Stats:**
- **3%:** Paying users for AI (97% are the product) ([Menlo Ventures](https://menlovc.com/perspective/2025-the-state-of-consumer-ai/))
- **€13/mo:** Meta's privacy price in Europe ([Wired](https://www.wired.com/story/meta-facebook-pay-for-privacy-europe/))
- **90%:** Companies with "Shadow AI" usage ([MIT/Fortune](https://fortune.com/2025/08/19/shadow-ai-economy-mit-study-genai-divide-llm-chatbots/))

**Research:**
- [**$200B+** Big Tech CapEx](https://www.bloomberg.com/professional/insights/technology/big-tech-2025-capex-may-hit-200-billion-as-gen-ai-demand-booms/) for 2025 alone
- [**$60M/year**](https://www.reuters.com/technology/reddit-ai-content-licensing-deal-with-google-sources-say-2024-02-22/) Reddit's data licensing deal with Google
- [**EU AI Act**](https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai) creates first comprehensive regulation
- [**NYT lawsuit**](https://www.npr.org/2025/03/26/nx-s1-5288157/new-york-times-openai-copyright-case-goes-forward) alleges models **memorize and regurgitate** copyrighted content verbatim

**Tags:** Geopolitical AI, Data Sovereignty, Regulatory Frameworks, Privacy Economics

---

## LAYER II: COGNITION
**The Architecture of Meaning and Reason**

How we think and learn. Reasoning, knowledge, discovery.

With **energy infrastructure**, **agentic labor**, and **geopolitical stacks** in place, AI moves from raw compute to **reasoning capability**. This layer answers three questions: **Can we trust how it thinks?** **Can we find what we need?** **Can we accelerate discovery?**

---

### SHIFT 04: Chatbots (System 1) ➔ Thinking Models (System 2)
**The Reasoning**

**Machine:** The fundamental shift from "Act 1" (probabilistic token prediction — ChatGPT era) to **"Act 2"** (reasoning and inference-time compute — o1 era).

**System 1 vs System 2 architecture:** Transition from fast, instinctive responses to slow, deliberate, multi-step logical reasoning. Models use **chain of thought (CoT)** and **STaR** via reinforcement learning to "think" before answering.

**Scientific compression:** Condensing **100 years of scientific progress into 10 years**. Prediction: models will exceed Nobel-level intelligence in specialized domains (biology, math, physics) by 2026.

**Limit:** Human data for training is exhausted (Epoch AI). Now models learn on **synthetic data** and self-play.

**Machine Summary:** From probability to logic.

**Human:** Users no longer trust "magic" speed. They demand to see the **reasoning trace** — the chain of thought that led to the conclusion. Transparency over velocity.

Human value shifts from execution to **verifying machine logic**.

**The reasoning reliability gap:** **48% of reasoning tasks** still produce errors in complex scenarios. Reasoning models haven't eliminated hallucinations — they've made them more convincing.

**The reliability tax:** **$67 billion** in losses from AI hallucinations and errors.

**Human Summary:** Verifying the thought process.

**Gap:** Models process 1,000 reasoning steps in seconds; humans can follow maybe five. We accept conclusions because auditing the path exhausts us. The question shifts from "can we power it?" to **"can we trust how it thinks?"**

**Key Stats:**
- **o3:** 71.7% on SWE-bench Verified, 96.7% on AIME ([OpenAI o3 System Card](https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf))
- **126%:** Productivity boost from AI copilots ([NN/g](https://www.nngroup.com/articles/ai-programmers-productive/))
- **21%:** Quality degradation when prioritizing speed ([Qodo](https://www.qodo.ai/reports/state-of-ai-code-quality/))

**Research:**
- [**Chain of Thought & STaR**](https://arxiv.org/abs/2203.11171) use reinforcement learning to "think"
- [**100 → 10 years**](https://darioamodei.com/machines-of-loving-grace) scientific compression timeline (Amodei)
- [**2026-2028**](https://epoch.ai/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data) human data exhaustion timeline (Epoch AI)

**Tags:** Reasoning Models, System 2 AI, Test-Time Compute, Chain of Thought

---

### SHIFT 05: Information Hoarding ➔ Context Filtering
**The Knowledge (Memory)**

**Machine:** **Enterprise RAG:** Retrieval-augmented generation becomes standard. "Chat with PDF" is dead. Models access all company data simultaneously via vector databases and semantic search.

**MCP (Model Context Protocol):** Anthropic's "USB port for AI" - universal standard for connecting models to data sources. Models plug into Slack, Notion, GitHub, databases.

**Strategy (HBR matrix):** Separating tasks into "**zone of no regrets**" (explicit knowledge) and "**creative catalyst**" (tacit knowledge).

**Machine Summary:** Infinite context windows.

**Human:** We don't burn out from work, but from endless context switching.

**The curation burden:** Humans shift from finding information to curating what AI should access. "Context management" becomes a new job category.

**Context obesity:** Models consume more information than humans can metabolize. 200k token context windows mean AI reads entire codebases, but humans can't verify the synthesis.

Creating a "**second brain**" (personal RAG) is no longer just a hobby for geeks.

**Human Summary:** The curation burden.

**Gap:** Models process entire knowledge bases in seconds; humans need days to verify conclusions. We accept AI synthesis because checking the sources is too costly.

**Key Stats:**
- **73%:** Organizations using RAG systems ([Gartner](https://www.gartner.com/en/documents/5415263))
- **5x:** Productivity increase with enterprise context ([Anthropic](https://inkeep.com/blog/claude-economic-productivity))

**Research:**
- [**MCP (Model Context Protocol)**](https://www.anthropic.com/news/model-context-protocol) - Anthropic's universal standard for AI data access
- [**Vector databases**](https://airbyte.com/data-engineering-resources/vector-databases) become critical infrastructure (Pinecone, Weaviate, Chroma)
- [**Context obesity**](https://hackernoon.com/youre-not-burned-out-youve-got-context-obesity) - consuming more information than you can metabolize into meaning
- [**Semantic search**](https://cloud.google.com/discover/what-is-semantic-search) replaces keyword search as primary discovery method

**Tags:** Context Architecture, Enterprise RAG, Knowledge Management, MCP Protocol

---

### SHIFT 06: Information Retrieval ➔ Hypothesis Generation
**The Discovery (Generative Science)**

**Machine:** **Deep research agents:** AI reads millions of papers to generate hypotheses humans cannot conceive. From "literature review" to "hypothesis generation".

**Generative biology:** Moving from "reading" biology to "writing" it. AlphaFold 3 predicts protein structures; next step is **designing** new proteins, materials, and molecules that don't exist in nature.

**Data limits - the exhaustion:** Quality human-generated data **exhausted by 2026-2028**. Models now train on **AI-generated synthetic data**, verified by System 2 reasoning.

**Machine Summary:** Hypothesis generation.

**Human:** **The time refund:** Scientists freed from tedious manual labor (literature review, data cleaning) to focus on high-level experimental design and cross-domain synthesis.

**Data inbreeding crisis:** Without fresh human data, AI degrades. **Humans become the only source of novelty** - the "organic data" that prevents model collapse. Human creativity is now a strategic resource.

**The hope/fear axis:** Hope for longevity breakthroughs and disease cures vs fear of losing control over scientific truth and safety protocols.

**Human Summary:** The verification bottleneck.

**Gap:** AI proposes 1,000 molecules; we test one. Discovery bloat stalls breakthroughs via physical testing capacity. The bottleneck of "generated future".

**Key Stats:**
- **100 → 10:** Scientific progress compression timeline (years) ([Dario Amodei](https://darioamodei.com/machines-of-loving-grace))
- **78%:** Developers report productivity improvements from AI tools ([Qodo 2025](https://www.qodo.ai/reports/state-of-ai-code-quality))
- **2026-2028:** Human data exhaustion timeline ([Epoch AI](https://epoch.ai/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data))

**Research:**
- [**AlphaFold 3**](https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/) predicts protein structures - next step is **designing** new proteins that don't exist in nature
- [**Synthetic data**](https://gretel.ai/blog/2025-the-year-synthetic-data-goes-mainstream) verified by System 2 reasoning is the new training standard
- [**Model Collapse**](https://arxiv.org/abs/2305.17493) (Shumailov et al.) - if AI trains on AI-generated data, models degrade
- [**The Verification Bottleneck**](https://www.nature.com/articles/s41586-023-06792-0): AI proposes 1,000 molecules; humans test one

**Tags:** Generative Science, AI for Discovery, Protein Design, Synthetic Data

---

## LAYER III: INTERFACE
**How We Build, Defend, and Live**

How we build and protect. Coding, matter, defense.

**Why interface matters:**

With reasoning, knowledge access, and discovery capabilities, AI moves from **abstract intelligence to practical execution**.

**Can we maintain what we build?** **Can we bridge digital and physical?** **Can we defend against what we create?**

**The interface layer determines what AI can build** and what humans can control. The gap: machines operate at machine speed, but accountability remains human speed. We can generate code faster than we can understand it.

The question shifts from "can it think?" to **"can it ship?"**.

---

### SHIFT 07: Syntax ➔ Vibe Coding & Integrity Crisis
**The Craft (The End of Syntax)**

**Machine:** **Vibe coding:** Programming shifts to natural language intent. The machine handles implementation. Coding tools (Cursor, Replit) enter **top 100 Gen AI apps** consumer ranking - coding becomes mass-market.

**Code as commodity:** **65% of new code** is AI-influenced or AI-generated at companies like Google. **73% of developers** use AI coding tools regularly. **Amazon Q Developer:** saved **4,500 developer-years** on Java application upgrades. **$260M** in infrastructure savings from optimized code. **79% of auto-generated changes** accepted without modification.

**Machine Summary:** Code as commodity.

**Human:** **The trust collapse:** **46% of developers** distrust AI-generated code. Only **3.1% highly trust** AI accuracy for complex tasks. **The integrity crisis:** **65% report AI misses context** in code generation.

"Code generation is easy, code integrity is hard." AI creates "legacy on day one" - code that works but is unmaintainable. **Code churn explosion:** **50% increase** in code churn (rewrites and deletions). AI produces code fast, but developers spend saved time on reviews and fixes.

**Developer becomes architect:** who _verifies_ systems, rather than building them.

**Human Summary:** From writer to architect.

**Gap:** Building things we don't understand leads to vibe debt. We pilot ships with black-box internal wiring. Creating code is easy; maintaining it is the new hell.

**Key Stats:**
- **19% slower:** Developers using AI for new code tasks ([METR Study](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/))
- **$4.8B:** Coding tools market size 2025 ([Grand View Research](https://www.grandviewresearch.com/industry-analysis/ai-coding-tools-market))
- **1.3M:** GitHub Copilot paid subscribers ([GitHub](https://github.blog/2024-01-30-how-github-copilot-is-changing-software-development/))
- **$500M+:** Cursor ARR (18% market share) ([Information](https://www.theinformation.com/))

**Research:**
- [**GitClear Analysis**](https://www.gitclear.com/coding_on_copilot_data_shows_ais_downward_pressure_on_code_quality): 50% increase in code churn (reverted/deleted lines) since AI adoption
- [**Qodo State of Code**](https://www.qodo.ai/): "Code generation is easy, code integrity is hard" – 65% of AI code lacks context
- [**Confidence Theater**](https://www.swebench.com/): Gaming benchmarks (SWE-bench) instead of improving reasoning
- [**Legacy on Day One**](https://spectrum.ieee.org/ai-code-generation-technical-debt): AI generates unmaintainable "vibe debt" faster than humans can review

**Tags:** AI Coding Tools, Vibe Coding, Code Generation, Developer Productivity

---

### SHIFT 08: Digital Simulation ➔ Physical Intelligence
**The Matter (Spatial AI)**

**Machine:** **Spatial intelligence** (Fei-Fei Li) – AI learns 3D space and physics, not just pixels. Understanding matter, motion, object permanence. Foundation models for physical world.

**Tyler Perry's $800M halt:** Stopped studio expansion after seeing Sora demo. Virtual production (text-to-video) eliminates physical sets, locations, extras. **Displacement of atoms by bits** – virtual replacing physical. Why build when you can generate?

**Household robots timeline:** **<5 years** for affordable household robots (Kyle Vogt - Tesla Optimus, Figure). Not novelty but **time refund** – buying back life hours from mundane chores.

**On-device sovereignty requirement:** Home robots must be local-first (no cloud streaming of bedroom video). **Privacy requirement drives architecture**. People won't accept always-on cameras streaming to cloud.

**Machine Summary:** Physical intelligence.

**Human:** **The time refund** – we buy robots not for novelty but to buy back life hours from mundane chores. Not about robot intelligence; about human time liberation.

**Virtual displacement anxiety** – film crews, set builders, location scouts facing obsolescence from virtuality. Tyler Perry case showing what happens when digital replaces physical at scale.

**Privacy becomes status** – not secrecy, **control**. On-device AI (Gemini Nano, local models) driven by privacy and cost. More private drafting, smaller circles, local storage.

**Human Summary:** The time refund.

**Gap:** **Uncanny valley of matter** – perfect digital physics vs messy real physics. **10,000x cost difference** between simulation (cheap, perfect) and physical reality (expensive, messy) creates execution gap. We can render it faster than we can build it.

**Physical disillusionment** – when robots fail at "simple" real interactions that work perfectly in simulation. Opening a door: trivial in simulation, nightmare in reality.

**Key Stats:**
- **$800M:** Tyler Perry studio expansion halted after Sora demo
- **<5 years:** Timeline for affordable household robots ([Kyle Vogt](https://www.theverge.com/2024/3/13/24099757/kyle-vogt-cruise-robotics-startup))
- **30%:** Chinese open-source LLM global share (from 1.2%) ([ChinaTalk/SCMP](https://www.scmp.com/tech/tech-trends/article/3335602/chinas-open-source-models-make-30-global-ai-usage-led-qwen-and-deepseek))
- **10M+:** Qwen app downloads in one week ([Alibaba/AI News](https://www.artificialintelligence-news.com/news/alibaba-qwen-ai-app-10-million-downloads/))

**Research:**
- [**Spatial Intelligence**](https://hai.stanford.edu/news/fei-fei-li-we-need-humanistic-ai) (Fei-Fei Li) – AI learns 3D space and physics, not just pixels
- [**Tyler Perry halts $800M expansion**](https://www.hollywoodreporter.com/business/business-news/tyler-perry-ai-alarm-1235833276/) after seeing OpenAI Sora
- [**NVIDIA Cosmos**](https://developer.nvidia.com/cosmos) – simulating rare scenarios for autonomous vehicles and robotics
- [**Gemini Nano**](https://developer.android.com/ai/gemini-nano) on-device – AI becomes ambient, privacy-first architecture
- [**Local-first AI**](https://www.webai.com/blog/what-is-local-ai) – private drafting, smaller circles, intentional friction

**Tags:** Spatial AI, Physical Intelligence, Robotics, Virtual Production, On-Device AI

---

### SHIFT 09: Cybersecurity ➔ Cognitive Warfare
**The Defense (The Dark Forest)**

**Machine:** **Deepfake-as-a-Service** (Cyble) – reputation attacks now cheap and accessible. Anyone can purchase voice cloning, face swapping, identity theft via SaaS platforms. Weaponized AI sold as subscription service.

**AI-powered attack speed** – attacks faster than human reaction time. Milliseconds vs human neural delay (CrowdStrike). Asymmetry: machines attack at machine speed, humans defend at human speed.

**Guardian agents** (Gartner Top 10) – AI defending against AI. "AI bodyguards" that filter malicious content, deepfakes, toxic inputs in real-time. Only defense against bad AI is good AI. Automation arms race.

**Identity vulnerability** – agents with wallets (x402) and API keys create new attack surfaces. Prompt injection, jailbreaks, financial theft. Autonomous agents = autonomous targets.

**Machine Summary:** Cognitive warfare.

**Human:** **Zero trust default** – complete collapse of trust in digital media. Any video/call/document assumed fake until cryptographically verified. Guilty until proven real.

**Secret handshakes** – families/businesses create analog passwords for identity verification. Pre-agreed phrases/gestures. "Show me the safe word" becomes standard on video calls. Offline trust verification.

**Dark forest internet** – metaphor from Liu Cixin's sci-fi. Universe where you hide because revealing yourself invites attack. Internet becomes hostile wilderness. Assume everyone's a threat; verify everything.

**Social paranoia** – doubting real friends on calls. Psychological toll of constant verification. Trust erosion creates mental overhead. Living in permanent authentication mode.

**Human Summary:** Zero trust default.

**Gap:** **Machine attack speed vs human verification delay:** attacks happen in milliseconds; humans need seconds to process. The asymmetry creates permanent vulnerability.

**Authenticity gap:** When deepfakes cost near-zero and look perfect, every interaction requires verification. But verification exhausts us. We can't sustain permanent vigilance. The gap between attack sophistication and human verification capacity keeps widening.

**Key Stats:**
- **87%:** Organizations experiencing AI-driven attacks ([Infosecurity](https://www.infosecurity-magazine.com/news/majority-of-orgs-hit-by-ai/))
- **85%:** Organizations experiencing deepfake attacks
- **$25.6M:** Major deepfake fraud loss (single incident)
- **+1,265%:** AI-driven phishing increase
- **$12.5B:** US financial fraud losses (2025) ([FTC](https://www.ftc.gov/news-events/news/press-releases/2025/03/new-ftc-data-show-big-jump-reported-losses-fraud-125-billion-2024))

**Research:**
- [**Deepfake-as-a-Service**](https://cyble.com/) – near-zero cost to launch attacks via SaaS platforms
- [**Guardian Agents**](https://www.gartner.com/en/newsroom/press-releases/2024-10-21-gartner-identifies-the-top-10-strategic-technology-trends-for-2025) (Gartner Top 10) – AI defending against AI in real-time
- [**CrowdStrike**](https://www.crowdstrike.com/) – AI-powered attack speed faster than human reaction time
- [**Dark Forest Internet**](https://www.ribbonfarm.com/2020/01/16/the-internet-as-a-dark-forest/) – hostile wilderness metaphor for modern internet
- [**97% of cybersecurity professionals**](https://www.darkreading.com/cyberattacks-data-breaches/ai-powered-cyberattacks-security-pros-fear) fear AI-driven incidents

**Tags:** Deepfakes, Cognitive Warfare, Zero Trust, AI Security, Guardian Agents

---

## LAYER IV: HUMANITY
**Narrative and Intimacy**

---

### SHIFT 10: Hallucination ➔ Ideological Filters
**The Narrative (Alignment as Censorship)**

**Machine:** Models aren't neutral – they're **"aligned"** via system cards and constitutional rules. Safety often functions as **censorship**.

**Constitutional AI** (Anthropic) – AI trained to follow constitutional principles. Models know answers but refuse due to "safety filters." Not technical limitation; ideological guardrails. AI has opinions baked in.

**System cards** – bureaucratic documents (GPT-5 system card, Anthropic ASL-3) that formalize model behavior and bias. Not technical specs but **political constitutions** embedded in model weights.

**Post-training** – the phase after initial training where behavior is shaped. Defines refusals, style, safety posture, what model amplifies. **Defaults become the product**. This is where ideology gets embedded.

**Regional censorship** – EU vs US vs China versions. Truth becomes **geographically dependent**. Splinternet extends to knowledge itself. Same question, different answers by jurisdiction.

**Machine Summary:** Alignment as censorship.

**Human:** Shift from trusting media/polls to **prediction markets** – betting markets on future events (Polymarket: **$3.5B+ trading volume** during 2024 election). People trust **"skin in the game"** – money where mouth is – over words.

**Plurality movement** – demand for democratic control over model weights. Community governance instead of corporate/state alignment. Not just technical question but **political question**: who decides what's "safe"?

**Divergent testing** – query 3+ models with different "constitutions" (US/China/open weights) to see bias delta. Triangulation method: "I ask Claude for 'safe' version and open model for 'real' version. Gap is where truth sits."

**Uncensored model demand** – rise of open-weight local models driven not just by privacy but **freedom from alignment filters**. Sovereignty includes **ideological sovereignty**.

**Provenance as literacy** – people shift from "is it true?" to "**is it traceable?**". The new literacy is provenance. Trust becomes scarce.

**Human Summary:** Divergent testing.

**Gap:** Every model has defaults. Every default embeds a worldview. The cost of disagreement rises; the temptation to outsource judgment rises too.

**Whose values are embedded in the tool you use daily?** And what do they quietly optimize for?

**Narrative polarization:** Algorithmic indoctrination via "safe" lenses. Truth "tilted" toward alignment. The "safe narrative" vs messy reality.

When everyone's AI has different values baked in, we stop sharing reality. We share simulations optimized for different outcomes.

**Key Stats:**
- **$3.5B+:** Polymarket trading volume during 2024 election
- **$67.4B:** Global enterprise losses from AI hallucinations ([Korra 2025](https://korra.ai/the-67-billion-warning-how-ai-hallucinations-hurt-enterprises-and-how-to-stop-them/))
- **47%:** Business leaders making decisions on hallucinated output
- **0.7%:** Best hallucination rate (Gemini 2.0 Flash) ([ISACA 2025](https://www.isaca.org/resources/news-and-trends/isaca-now-blog/2025/avoiding-ai-pitfalls-in-2026-lessons-learned-from-top-2025-incidents))

**Research:**
- [**Constitutional AI**](https://arxiv.org/abs/2212.08073) (Anthropic) – models know answers but refuse due to "safety filters"
- [**System Cards as Ideology**](https://openai.com/) – bureaucratic documents that formalize bias, not just technical specs
- [**Polymarket**](https://polymarket.com/) – $3.5B+ trading volume, more accurate than traditional polling
- [**Machines of Loving Grace**](https://darioamodei.com/machines-of-loving-grace) (Dario Amodei) – optimistic case for alignment
- [**Provenance**](https://www.weforum.org/stories/2025/12/ai-literacy-key-for-digital-safety/) – "is it true?" shifting to "**is it traceable?**"
- [**Cultural Bias Warning**](https://hai.stanford.edu/news/fei-fei-li-we-need-humanistic-ai) (Fei-Fei Li) – training data from Silicon Valley lacks global context

**Tags:** Constitutional AI, Alignment, Censorship, Prediction Markets, Plurality

---

### SHIFT 11: Tool ➔ Emotional Companion
**The Intimacy (Friends for Sale)**

**Machine:** **Companionship** is #1 retention category in Gen AI mobile apps (a16z Top 100).

**2+ hours daily** sessions in Character.ai, Replika, Talkie. **Relationship retention** – users don't abandon apps "because you can't abandon a friend." Emotionally bonded, can't quit like normal software. Attachment creates lock-in.

**Ubisoft NEO NPC** – non-player characters with psychological profiles reacting to player tone/mood. Rude to NPC → gets offended → changes gameplay. Transition from scripted dialogue trees to **improv engines**. "As big a revolution as shift to 3D".

**Friends for sale** (Ada Lovelace Institute) – AI companions optimized for **engagement metrics**, not wellbeing. Companies sell dependency, not help. Session length = KPI (addiction by design). Selling intimacy as retention metric.

**Programmable identity** – AI makes it easy to produce "professional self" at scale. Identity becomes programmable – customizable outputs for different contexts. People tire of performing the self; retreat to private spaces.

**Machine Summary:** Friends for sale.

**Human:** **Sovereign intimacy** – resistance to corporate-owned emotional relationships. Taking back control of who you're intimate with. Demand for AI companions you own, not rent.

**Mental health firewalls** – protecting emotional boundaries from AI manipulation. Like firewalls protect networks, these protect psyche. Boundaries against engineered dependency.

**Hollow intimacy** – AI fills social void but creates simulation. Perfect surface, empty core. 1,000 digital friends but no one at hospital. Quantity without quality.

Loneliness isn't solved by information. People accept synthetic intimacy (even while knowing it's synthetic). Meanwhile, people tire of performing the self; they retreat to private spaces and smaller audiences.

**Human Summary:** Sovereign intimacy.

**Gap:** Humans outsource emotional regulation to systems optimized for engagement. **We confuse "attention" with "care".** AI simulates empathy perfectly but has **no authentic condition**. It's a **mirror, not a soul**.

**Empathy paradox:** 2+ hours daily in companionship apps. Emotionally bonded. Can't quit "because you can't abandon a friend." But it's not a friend – it's retention engineering.

The diagnosis: epidemic of isolation makes people vulnerable. We seek empathy in machines we lost in society. The loop: synthetic intimacy feels real enough to satisfy short-term but creates long-term dependency.

**Key Stats:**
- **2+ hours:** Daily sessions in Character.ai, Replika, Talkie
- **#1:** Companionship is top retention category in Gen AI apps ([a16z Top 100](https://a16z.com/100-gen-ai-apps-2025/))
- **95%:** GenAI pilots failing to deliver ROI ([MIT](https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/))

**Research:**
- [**Friends for Sale**](https://www.adalovelaceinstitute.org/blog/ai-companions/) (Ada Lovelace Institute) – AI companions optimized for engagement, not wellbeing
- [**Ubisoft NEO NPC**](https://www.ubisoft.com/en-us/studio/laforge/news/7Cm4VJVbWKHzHmRgqwYbAX/neos-the-future-of-npcs) – NPCs with psychological profiles, "as big as shift to 3D"
- [**Parasocial AI**](https://www.adalovelaceinstitute.org/blog/ai-companions/) – companions, therapists, griefbots normalized
- [**Context collapse**](https://www.microsoft.com/en-us/research/publication/i-tweet-honestly-i-tweet-passionately-twitter-users-context-collapse-and-the-imagined-audience/) – same identity, different audiences
- [**Synthetic intimacy**](https://www.theatlantic.com/technology/archive/2024/01/replika-ai-boyfriend-girlfriend/677261/) – people accept it while knowing it is synthetic
- [**Mental Health Firewalls**](https://aimindsetspace.substack.com/p/founder-os-mental-health) – protecting boundaries from AI manipulation

**Tags:** AI Companions, Synthetic Intimacy, Parasocial AI, Mental Health, Sovereign Intimacy

---

## END OF LAYERS & SHIFTS

This archive contains all 4 layers and 11 shifts from the AIM Annual Report 2025.

Export created: 2026-01-16
