---
aliases:
  - Context Gap v3
  - Final Text
tags:
  - type/content
  - project/aim-report
date: 2025-12-31
author: Ray Svitla
refs:
  - "[[Agents]]"
  - "[[{AIM report} {data} Loops Mapping – 2025-12-23]]"
  - "[[{AIM report} {data} Key Metrics – 2025-12-23]]"
---

# slide 0 — cover

**the context gap**  
**ai is accelerating. humans are buffering.**

a yearly reset artifact by **AI Mindset** + community.  
_a sovereignty reset for people running their own life._

---

# slide 1 — a note from the team

we made this because 2025 didn’t feel like a year.

it felt like the year **context became expensive**.

machines got faster at producing outputs.  
humans got slower at holding meaning, attention, and coherent direction.

this isn’t a “trends” deck.  
it’s closer to a navigation tool.

we’re not trying to predict the future with confidence theater.  
we’re trying to show **what changed**, **why it matters**, and **what the human layer can do** — so you can make better calls in 2026.

— ai mindset (research + labs team)

---

# slide 2 — what this is (and isn’t)

**this is:** a paired map.

you’ll go through **10 paired loops**.

- **machine signal** (capability / deployment / economics)
    
- **human signal** (cognition / identity / culture)
    
- **the context gap** (where coordination breaks)
    

**this isn’t:**

- a hype deck
    
- a moral panic
    
- a consulting pdf that says nothing new
    

---

# slide 3 — what we mean by “context gap”

**context gap = the distance between:**

1. the context a system needs to act well  
    and
    
2. the context a human can actually hold without degrading decisions.
    

and the real losses:

- **time** (the non‑renewable one)
    
- **money** (busy ≠ effective)
    
- **reputation** (sloppy decisions, missed nuance)
    

---

# slide 4 — the thinkers & research lines behind the frame

this is the backbone behind the **150+** papers, benchmarks, policy docs, and infra reports we reviewed.

- **attention & scarcity** (Herbert Simon): attention becomes the bottleneck.
    
- **cognition under load** (cognitive load / hci; Kahneman as a metaphor): more inputs → worse judgment; “fast guess” vs “slow verify.”
    
- **acceleration & identity** (Toffler → Rosa): speed reshapes norms and self.
    
- **tools as minds** (Clark & Chalmers): tools extend cognition; partnership beats replacement.
    
- **sovereignty as cultural tech** (Hirschman; Balaji): “exit” becomes everyday language for autonomy
    
---

# slide 5 — our signal base (ai mindset)

we trust **signals** — especially signals with a feedback loop.

**ai mindset labs (2025):**

- **6 labs** / **200+ graduates** / **23+ countries**
- **100+ live hours**
- **67% completion**

we built this report as the yearly reset artifact for the **ai mindset + community** ecosystem — and then pressure-tested the ideas in practice.

thanks: Alex P, Ray Svitla, Sergei Khabarov, and Anca for finishing this over the christmas holidays.

sources:

- ai mindset labs (overview) [https://aimindset.org/ai-mindset-w25](https://aimindset.org/ai-mindset-w25)
    

---

# slide — loop 1: system‑2 reasoning

**machine signal**  
“chat” is turning into **delegation**.  
agents don’t just answer — they do (plan, act, call tools, ship).  
“slow thinking” moves from research concept to product feature: fewer obvious failures, more consistent multi‑step output.

**human signal**  
people don’t trust “magic.” they trust **auditable work**.  
the moment an agent touches [money](https://www.x402.org/), customers, or reputation, humans demand: _show me your steps_.

**the context gap**  
agents operate at machine speed, but accountability remains human speed.  
verification becomes ethics — “can you just approve this?” becomes the most expensive sentence in a company.

sources:

- li et al. — _reasoning llms survey (system 1 / system 2 framing)_ [https://arxiv.org/abs/2502.17419](https://arxiv.org/abs/2502.17419)
- openai — _introducing swe-bench verified_ (evaluation + auditability pressure) [https://openai.com/index/introducing-swe-bench-verified/](https://openai.com/index/introducing-swe-bench-verified/)
- internet-native payments for ai agents (x402) [https://www.x402.org/](https://www.x402.org/)

---

# slide — loop 2: orchestration layers

**machine signal**  
the center of gravity moves from chat to **agentic workflows**: systems that call tools, execute steps across software, and coordinate across services.

**human signal**  
overload becomes baseline: too many threads, tools, notifications, pseudo‑tasks.  
every new layer adds fear: “who owns the workflow?” “where does my data go?” “can i exit? ◡̈”

**the context gap**  
when systems connect, context leaks across apps — humans can’t see the full graph, but remain responsible for outcomes.  
the question becomes: **who is the author of outcomes?**

sources:

- anthropic — _model context protocol (mcp)_ [https://www.anthropic.com/news/model-context-protocol](https://www.anthropic.com/news/model-context-protocol)
- gartner — _top 10 strategic technology trends for 2025_ (agentic ai) [https://www.gartner.com/en/newsroom/press-releases/2024-10-21-gartner-identifies-the-top-10-strategic-technology-trends-for-2025](https://www.gartner.com/en/newsroom/press-releases/2024-10-21-gartner-identifies-the-top-10-strategic-technology-trends-for-2025)
- ai mindset — _you’re not burned out, you’ve got context obesity_ [https://hackernoon.com/youre-not-burned-out-youve-got-context-obesity](https://hackernoon.com/youre-not-burned-out-youve-got-context-obesity)

---

# slide — loop 3: sovereign ai

**machine signal**  
regulation matures. institutions define “unacceptable risk.”  
sovereign ai becomes strategy: data residency, regulated stacks, local inference, compliant clouds.  
“where data lives” becomes as important as “what the model can do.”

**human signal**  
a personal version emerges: neo‑sovereignty.  
people build their own spaces (private notes, smaller circles, local tools) because public feeds feel noisy, extractive, increasingly synthetic.

**the context gap**  
trust splits: people want innovation and guarantees.  
for orgs it’s compliance and risk; for individuals it’s privacy, boundaries, and control over the context that shapes thinking.

sources:

- eur-lex — _regulation (eu) 2024/1689 (artificial intelligence act)_ [https://eur-lex.europa.eu/eli/reg/2024/1689/oj/eng](https://eur-lex.europa.eu/eli/reg/2024/1689/oj/eng)
- mckinsey — _accelerating europe’s ai adoption: the role of sovereign ai_ [https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/accelerating-europes-ai-adoption-the-role-of-sovereign-ai](https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/accelerating-europes-ai-adoption-the-role-of-sovereign-ai)

---

# slide — loop 4: data wall

**machine signal**  
high‑quality human data is finite; marginal gains get expensive.  
training leans harder on synthetic data and distillation.  
as synthetic output floods the environment, “evidence” becomes a formatting problem: it can look right before it is right.

**human signal**  
trust becomes scarce.  
people shift from “is it true?” to “is it traceable?”  
the new literacy is provenance.

**the context gap**  
machines can manufacture infinite text and images.  
humans can’t manufacture infinite meaning.  
the ratio collapses.

sources:

- epoch ai — _limits of llm scaling based on human-generated data_ [https://epoch.ai/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data](https://epoch.ai/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data)
    
- shumailov et al. — _the curse of recursion: training on generated data makes models forget_ (arXiv, 2023) [https://arxiv.org/abs/2305.17493](https://arxiv.org/abs/2305.17493)
    
- ai mindset field note — _team knowledge system_ [https://aimindsetspace.substack.com/p/ai-ark-knowledge-system](https://aimindsetspace.substack.com/p/ai-ark-knowledge-system)
    

---

# slide — loop 5: on‑device models ↔ privacy as status

**machine signal**  
smaller models get good enough and spread everywhere (on devices, at the edge, inside apps).  
ai becomes ambient — less a destination, more a layer.

**human signal**  
privacy becomes status. not secrecy — control.  
more private drafting, smaller circles, local storage, intentional friction against performative posting.

**the context gap**  
when ai is everywhere, boundaries become the differentiator.  
**if everything can be processed, the premium shifts to what you keep**

sources:

- android developers blog — _the latest gemini nano with on-device ml kit genai apis_ [https://android-developers.googleblog.com/2025/08/the-latest-gemini-nano-with-on-device-ml-kit-genai-apis.html](https://android-developers.googleblog.com/2025/08/the-latest-gemini-nano-with-on-device-ml-kit-genai-apis.html)
    
- wired — _meta is asking people in europe to pay for privacy_ [https://www.wired.com/story/meta-facebook-pay-for-privacy-europe/](https://www.wired.com/story/meta-facebook-pay-for-privacy-europe/)
    
- ico — _data lives: year 2 report_ (pdf) [https://ico.org.uk/media2/m2maphry/ico-data-lives-year-2-report.pdf](https://ico.org.uk/media2/m2maphry/ico-data-lives-year-2-report.pdf)
    

---

# slide — loop 6: compute & energy ↔ return of physics

**machine signal**  
ai isn’t just software. it’s infrastructure: chips, energy, cooling, geopolitics.  
even digital gods need electricity.  
energy and compute become the regulator of progress.

**human signal**  
energy economics turns personal: burnout realism, fatigue, “time hangover,” sharper awareness of biological limits.  
people begin optimizing for sustainability, not maximum output.

**the context gap**  
data centres become local political issues; your “cloud” starts to feel like a land dispute.

philosophical note: thermodynamics returns as a hidden governor — you can’t out‑optimize scarcity forever.

sources:

- iea — _energy supply for ai_ [https://www.iea.org/reports/energy-and-ai/energy-supply-for-ai](https://www.iea.org/reports/energy-and-ai/energy-supply-for-ai)
    
- reuters — _ai data centers are forcing obsolete ‘peaker’ power plants back into service_ (2025-12-23) [https://www.reuters.com/business/energy/ai-data-centers-are-forcing-obsolete-peaker-power-plants-back-into-service-2025-12-23/](https://www.reuters.com/business/energy/ai-data-centers-are-forcing-obsolete-peaker-power-plants-back-into-service-2025-12-23/)
    

---

# slide — loop 7: coding agents (roi beachhead) ↔ authorship anxiety

**machine signal**  
coding becomes the first broadly proven agent category: systems write, refactor, test, ship.  
the value is measurable; adoption is fast.

**human signal**  
authorship anxiety rises: “what’s mine if the machine did it?”  
fear of skill atrophy, status loss, erosion of craft.

**the context gap**  
when labor gets cheaper, identity gets more expensive.  
in a world where output is abundant, authorship becomes less about typing and more about owning decisions.

sources:

- openai — _introducing swe-bench verified_ [https://openai.com/index/introducing-swe-bench-verified/](https://openai.com/index/introducing-swe-bench-verified/)
    
- anthropic — _swe-bench sonnet_ [https://www.anthropic.com/research/swe-bench-sonnet](https://www.anthropic.com/research/swe-bench-sonnet)
    
- ai mindset field note — _coding with gemeini 3_ [https://t.me/ai_mind_set/282](https://t.me/ai_mind_set/282)
    

---

# slide — loop 8: regional frames

**machine signal**  
ai progress is global, but governance and deployment realities differ by region — policy, procurement, infrastructure, and institutional trust.

**human signal**  
moral frames diverge:

- us: frontier / market
    
- eu: rights / compliance
    
- others: utility / stability / state capacity (varies)
    

**the context gap**  
a global story can’t be one voice. the same capability reads as liberation, risk, or stability tool depending on the frame.  
pluralism is not optional — if you ignore frames, you misunderstand people (or get misunderstood).

sources:

- pew research center — _trust in the eu, u.s. and china to regulate ai_ [https://www.pewresearch.org/2025/10/15/trust-in-the-eu-u-s-and-china-to-regulate-use-of-ai/](https://www.pewresearch.org/2025/10/15/trust-in-the-eu-u-s-and-china-to-regulate-use-of-ai/)
    
- stanford HAI — _ai index 2025: public opinion_ [https://hai.stanford.edu/ai-index/2025-ai-index-report/public-opinion](https://hai.stanford.edu/ai-index/2025-ai-index-report/public-opinion)
    
- european commission / op publications — _ai research publications in science_ [https://op.europa.eu/en/publication-detail/-/publication/4ee8799e-142c-11f0-b1a3-01aa75ed71a1/language-en](https://op.europa.eu/en/publication-detail/-/publication/4ee8799e-142c-11f0-b1a3-01aa75ed71a1/language-en)
    
- digital plurality project (plurality) [https://github.com/pluralitybook/plurality](https://github.com/pluralitybook/plurality)
    

---

# slide — loop 9: post‑training default values

**machine signal**  
post‑training defines behavior: refusals, style, safety posture, what a model tends to amplify.  
defaults become the product.

**human signal**  
values fragment.  
people cluster into micro‑realities and micro‑truths.  
the cost of disagreement rises; the temptation to outsource judgment rises too.

**the context gap**  
every model has defaults.  
every default embeds a worldview.

**the human question becomes:**  
whose values are embedded in the tool you use daily — and what do they quietly optimize for?

sources:

- ouyang et al. — _training language models to follow instructions with human feedback_ (InstructGPT, 2022) [https://arxiv.org/abs/2203.02155](https://arxiv.org/abs/2203.02155)
    
- bai et al. — _constitutional ai: harmlessness from ai feedback_ (2022) [https://arxiv.org/abs/2212.08073](https://arxiv.org/abs/2212.08073)
    
- _investigating local censorship_ (arXiv, 2025) [https://arxiv.org/pdf/2505.12625](https://arxiv.org/pdf/2505.12625)
    

---

# slide — loop 10: machine intimacy + programmable identity

**machine signal**  
ai moves from tool to relationship surface: companions, therapists, griefbots, parasocial loops.  
in parallel, ai makes it easy to produce a “professional self” at scale — identity becomes programmable.

**human signal**  
loneliness isn’t solved by information.  
people accept synthetic intimacy (even while knowing it’s synthetic).  
meanwhile, people tire of performing the self; they retreat to private spaces and smaller audiences.

**the context gap**  
humans outsource emotional regulation to systems optimized for engagement.  
we confuse **“attention” with “care.”**

sources:

- ai mindset field note — _ai + mental health boundaries (founder os)_ [https://aimindsetspace.substack.com/p/founder-os-mental-health](https://aimindsetspace.substack.com/p/founder-os-mental-health)
    
- ada lovelace institute — _friends for sale: the rise and risks of ai companions_ (2025) [https://www.adalovelaceinstitute.org/blog/ai-companions/](https://www.adalovelaceinstitute.org/blog/ai-companions/)
    
- marwick & boyd — _context collapse and imagined audience_ (microsoft research) [https://www.microsoft.com/en-us/research/publication/i-tweet-honestly-i-tweet-passionately-twitter-users-context-collapse-and-the-imagined-audience/](https://www.microsoft.com/en-us/research/publication/i-tweet-honestly-i-tweet-passionately-twitter-users-context-collapse-and-the-imagined-audience/)
    

---

# slide — machines, summarized (2025 → 2026)

what changed in machines:

- from chat to **delegation** (agents + orchestration)
- from “more scale” to **better reasoning** (system‑2 behavior)
- from capability focus to **constraints** (trust, governance, energy)
- from one platform to **protocol layers** (connective tissue)
- from cloud-only to **ambient ai** (on‑device + edge)

---

# slide — humans, summarized (2025 → 2026)

what changed in humans:
- from consumption to **curation** (feeds → gardens)
- from optimism to **trust management** (provenance, receipts, auditability)
- from public posting to **private coherence** (smaller circles, intentional friction)
- from “more tools” to **more fatigue** (capacity gap)
- from “identity as output” to **identity as constraint**
    

---

# slide — call to agency

the wrong question is: “what is this doing to us?”  
the better question is:

**“what are we letting it do to us?”**

this is not a technological coup.  
it’s a voluntary abdication — a surrender of the burden of choice.

it can be reclaimed.  
but it must be reclaimed.

sources:

- tu wien — _perspectives on digital humanism (introduction)_ [https://dighum.ec.tuwien.ac.at/perspectives-on-digital-humanism/introduction/](https://dighum.ec.tuwien.ac.at/perspectives-on-digital-humanism/introduction/)
    

---

# slide — survival kit

in 2026, most people won’t lose to ai.  
they’ll lose to their own **defaults**.

your life already runs on configuration:

- what you say yes to without thinking
    
- what interrupts you without permission
    
- what you outsource because you’re tired
    
- what you believe because it was repeated
    

**constitution‑as‑code** = moving from “i’ll try” → “i have defaults.” a config file.

ai mindset field note: our “operating system” build (team knowledge system) lives here → [https://aimindsetspace.substack.com/p/ai-ark-knowledge-system](https://aimindsetspace.substack.com/p/ai-ark-knowledge-system)

sources:

- clark & chalmers — _the extended mind_ [https://consc.net/papers/extended.html](https://consc.net/papers/extended.html)
    
- tu wien — _the attention economy and the impact of ai_ [https://dighum.ec.tuwien.ac.at/perspectives-on-digital-humanism/the-attention-economy-and-the-impact-of-ai/](https://dighum.ec.tuwien.ac.at/perspectives-on-digital-humanism/the-attention-economy-and-the-impact-of-ai/)
    

---

# slide — community signals

they are **field signals**: real workflow shifts from [ai mindset space](https://aimindset.org/ai-mindset-community) that ground our 10 loops in lived experience.

- “i became a builder: i shipped in 30 minutes what stalled for 1.5 months.”  
    — Alexander Stashenko
    
- “two weeks of content in 30 minutes; transcripts in zero; apps deploy on prompts.”  
    — Nikolay Senin
    
- “ai moved from smart tool to full participant; i design pipelines, humans decide now.”  
    — Yakov Vasiliev
    
- “cursor and claude code turned me into a product automator; i vibe-coded real prototypes.”  
    — Natalya Savenkova
    
- “after sessions, output is a product: two voice commands plus mcp ship artifacts fast.”  
    — Dmitry Kompanets
    
- “i manage virtual developers: codex generates, claude verifies; legacy rewrites take days, not weeks.”  
    — Andrei Muntanion
    
- “llm roleplay is my reality simulator; i learn by ‘coffee chats’ with experts daily.”  
    — Artem Tereshin
    
- “i document corporate context end-to-end; llms use it to improve processes and strategy continually.”  
    — R_om
    
- “the product shift: hold the user’s hand, solve their task—don’t sell a universal tool.”  
    — Evgeniy
    
- “it reads like a chatgpt monolith: lots of ‘we,’ little risk, little responsibility, little concrete.”  
    — Andrei Shakhov
    

---

# slide — stay in the loop

if this artifact helped you name the friction — don’t lose the thread.

**stay connected with ai mindset:**

- **subscribe on substack** → get next resets, field notes, templates, and lab openings  
    [https://aimindsetspace.substack.com/](https://aimindsetspace.substack.com/)
    
- **explore the ecosystem** → labs, tools, community, artifacts  
    [https://aim-ecosystem-map.netlify.app/#](https://aim-ecosystem-map.netlify.app/#)
    
- **talk to us** → partnerships / speaking / labs for teams  
    [http://t.me/alex_named](http://t.me/alex_named)
    

_signals only. no spam. unsubscribe anytime._

---

# appendix — source shelf (curated)

keep this as a collapsible section on the website; in pdf it can be a final appendix.

## ai: capability, infra, adoption

- stanford HAI — _ai index 2025_ (pdf) [https://hai-production.s3.amazonaws.com/files/hai_ai_index_report_2025.pdf](https://hai-production.s3.amazonaws.com/files/hai_ai_index_report_2025.pdf)
    
- gartner — _top 10 strategic technology trends for 2025_ [https://www.gartner.com/en/newsroom/press-releases/2024-10-21-gartner-identifies-the-top-10-strategic-technology-trends-for-2025](https://www.gartner.com/en/newsroom/press-releases/2024-10-21-gartner-identifies-the-top-10-strategic-technology-trends-for-2025)
    
- anthropic — _model context protocol (mcp)_ [https://www.anthropic.com/news/model-context-protocol](https://www.anthropic.com/news/model-context-protocol)
    
- mcp spec hub [https://modelcontextprotocol.io/](https://modelcontextprotocol.io/)
    
- swe-bench ecosystem [https://www.swebench.com/](https://www.swebench.com/)
    
- openai — _introducing swe-bench verified_ [https://openai.com/index/introducing-swe-bench-verified/](https://openai.com/index/introducing-swe-bench-verified/)
    
- x402 — _internet-native payments for ai agents_ [https://www.x402.org/](https://www.x402.org/)
    

## data: limits + synthetic loops

- epoch ai — _limits of llm scaling (human data constraints)_ [https://epoch.ai/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data](https://epoch.ai/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data)
    
- shumailov et al. — _the curse of recursion / model collapse_ [https://arxiv.org/abs/2305.17493](https://arxiv.org/abs/2305.17493)
    

## humans: overload, trust, culture

- microsoft — _work trend index 2024_ [https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is-here-now-comes-the-hard-part](https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is-here-now-comes-the-hard-part)
    
- microsoft — _work trend index 2025_ [https://www.microsoft.com/en-us/worklab/work-trend-index/2025-the-year-the-frontier-firm-is-born](https://www.microsoft.com/en-us/worklab/work-trend-index/2025-the-year-the-frontier-firm-is-born)
    
- edelman — _2025 trust barometer (global report, pdf)_ [https://www.edelman.com/sites/g/files/aatuss191/files/2025-01/2025%20Edelman%20Trust%20Barometer_Final.pdf](https://www.edelman.com/sites/g/files/aatuss191/files/2025-01/2025%20Edelman%20Trust%20Barometer_Final.pdf)
    
- marwick & boyd — _context collapse / imagined audience_ (microsoft research) [https://www.microsoft.com/en-us/research/publication/i-tweet-honestly-i-tweet-passionately-twitter-users-context-collapse-and-the-imagined-audience/](https://www.microsoft.com/en-us/research/publication/i-tweet-honestly-i-tweet-passionately-twitter-users-context-collapse-and-the-imagined-audience/)
    
- wired — _meta is asking people in europe to pay for privacy_ [https://www.wired.com/story/meta-facebook-pay-for-privacy-europe/](https://www.wired.com/story/meta-facebook-pay-for-privacy-europe/)
    
- ico — _data lives: year 2 report_ (pdf) [https://ico.org.uk/media2/m2maphry/ico-data-lives-year-2-report.pdf](https://ico.org.uk/media2/m2maphry/ico-data-lives-year-2-report.pdf)
    

## governance / philosophy

- eur-lex — _ai act (regulation (eu) 2024/1689)_ [https://eur-lex.europa.eu/eli/reg/2024/1689/oj/eng](https://eur-lex.europa.eu/eli/reg/2024/1689/oj/eng)
    
- european commission / op publications — _ai research publications in science_ [https://op.europa.eu/en/publication-detail/-/publication/4ee8799e-142c-11f0-b1a3-01aa75ed71a1/language-en](https://op.europa.eu/en/publication-detail/-/publication/4ee8799e-142c-11f0-b1a3-01aa75ed71a1/language-en)
    
- tu wien — _perspectives on digital humanism_ [https://dighum.ec.tuwien.ac.at/perspectives-on-digital-humanism/](https://dighum.ec.tuwien.ac.at/perspectives-on-digital-humanism/)
    
- pew research center — _trust in the eu, u.s. and china to regulate ai_ (2025) [https://www.pewresearch.org/2025/10/15/trust-in-the-eu-u-s-and-china-to-regulate-use-of-ai/](https://www.pewresearch.org/2025/10/15/trust-in-the-eu-u-s-and-china-to-regulate-use-of-ai/)
    
- ouyang et al. — _training language models to follow instructions with human feedback_ (InstructGPT, 2022) [https://arxiv.org/abs/2203.02155](https://arxiv.org/abs/2203.02155)
    
- bai et al. — _constitutional ai: harmlessness from ai feedback_ (2022) [https://arxiv.org/abs/2212.08073](https://arxiv.org/abs/2212.08073)
    
- _investigating local censorship_ (arXiv, 2025) [https://arxiv.org/pdf/2505.12625](https://arxiv.org/pdf/2505.12625)
    
- digital plurality project (plurality) [https://github.com/pluralitybook/plurality](https://github.com/pluralitybook/plurality)
    

## frame: attention, cognition, acceleration, sovereignty

- Simon — _designing organizations for an information-rich world_ (1971, pdf) [https://www.nmh-p.de/wp-content/uploads/Simon-H.A._Designing-organizations-for-an-information-rich-world.pdf](https://www.nmh-p.de/wp-content/uploads/Simon-H.A._Designing-organizations-for-an-information-rich-world.pdf)
    
- Wu — _the attention merchants_ (publisher page) [https://www.penguinrandomhouse.com/books/234876/the-attention-merchants-by-tim-wu/](https://www.penguinrandomhouse.com/books/234876/the-attention-merchants-by-tim-wu/)
    
- Sweller — _cognitive load during problem solving: effects on learning_ (1988) [https://www.sciencedirect.com/science/article/pii/0364021388900237](https://www.sciencedirect.com/science/article/pii/0364021388900237)
    
- Mark et al. — _focused, aroused, but so distractible_ (chi, microsoft research pdf) [https://www.microsoft.com/en-us/research/wp-content/uploads/2016/10/p903-mark.pdf](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/10/p903-mark.pdf)
    
- Kahneman — _thinking, fast and slow_ (publisher page) [https://us.macmillan.com/books/9780374533557/thinkingfastandslow/](https://us.macmillan.com/books/9780374533557/thinkingfastandslow/)
    
- Toffler — _future shock_ (library citation) [https://search.library.wisc.edu/catalog/999466643102121/cite](https://search.library.wisc.edu/catalog/999466643102121/cite)
    
- Rosa — _social acceleration_ (columbia university press) [https://cup.columbia.edu/book/social-acceleration/9780231148344/](https://cup.columbia.edu/book/social-acceleration/9780231148344/)
    
- Clark & Chalmers — _the extended mind_ [https://consc.net/papers/extended.html](https://consc.net/papers/extended.html)
    
- Shneiderman — _human-centered ai_ (oxford university press) [https://global.oup.com/academic/product/human-centered-ai-9780192845290](https://global.oup.com/academic/product/human-centered-ai-9780192845290)
    
- Hirschman — _exit, voice, and loyalty_ (harvard university press) [https://www.hup.harvard.edu/books/9780674276604](https://www.hup.harvard.edu/books/9780674276604)
    
- Davidson & Rees‑Mogg — _the sovereign individual_ (simon & schuster) [https://www.simonandschuster.com/books/The-Sovereign-Individual/James-Dale-Davidson/9781797103389](https://www.simonandschuster.com/books/The-Sovereign-Individual/James-Dale-Davidson/9781797103389)
    
- Srinivasan — _the network state_ [https://thenetworkstate.com/](https://thenetworkstate.com/)
    

## machine intimacy

- ada lovelace institute — _friends for sale: the rise and risks of ai companions_ (2025) [https://www.adalovelaceinstitute.org/blog/ai-companions/](https://www.adalovelaceinstitute.org/blog/ai-companions/)
    

## ai mindset field notes (in this deck)

- _you’re not burned out, you’ve got context obesity_ [https://hackernoon.com/youre-not-burned-out-youve-got-context-obesity](https://hackernoon.com/youre-not-burned-out-youve-got-context-obesity)
    
- _team knowledge system (ai ark)_ [https://aimindsetspace.substack.com/p/ai-ark-knowledge-system](https://aimindsetspace.substack.com/p/ai-ark-knowledge-system)
    
- _coding with Gemini 3 [https://t.me/ai_mind_set/282](https://t.me/ai_mind_set/282)
    
- _ai + mental health boundaries (founder os)_ [https://aimindsetspace.substack.com/p/founder-os-mental-health](https://aimindsetspace.substack.com/p/founder-os-mental-health)
    

---