{
  "metadata": {
    "version": "v4",
    "title": "THE CONTEXT GAP",
    "year": "2025",
    "structure": "11 Tectonic Shifts in 4 Layers",
    "lastUpdated": "2026-01-14T20:48:03.410Z"
  },
  "slides": [
    {
      "title": "the context gap",
      "subtitle": "ai is accelerating. humans are changing.",
      "visual": "hero_cover",
      "layout": "story-scroll",
      "caption": "a yearly reset artifact by ai mindset + community.\na sovereignty reset for people running their own life.",
      "content": [
        "2025 wasn't just a year in the ai calendar. it was the moment **context became the most expensive resource on earth**. we called this report the context gap because it identifies the primary fracture in modern civilization: the distance between the volume of data a machine can generate and the amount of meaning a human can integrate without losing their agency, their sanity, or their will. **machines have conquered the complexity barrier. humans have hit the context wall.** ai is accelerating. humans are buffering. we are solving a fundamental crisis: **the loss of agency**. in a world where generating content, code, and ideas is effectively free, the act of verifying them has become a luxury. we are currently paying a **reliability tax** with our time and attention. if you cannot audit what the algorithm proposes, you are no longer a leader‚Äîyou are a passenger. this report is your perimeter defense against: **context obesity** (cognitive paralysis), **the reliability tax** ($67 billion in annual losses), **the responsibility void** (decisions by agents with no accountability), and **data inbreeding** (ai training on ai-generated data). we organize the 11 shifts into 4 layers because **ai transformation doesn't happen all at once** - it cascades through civilization in a specific order. **üß± layer i: foundation** - physics, economics, and power. **üß† layer ii: cognition** - reasoning, knowledge, discovery. **üõ°Ô∏è layer iii: interface** - coding, matter, defense. **‚ù§Ô∏è layer iv: humanity** - narrative and intimacy. each shift creates a **machine signal** ‚Üî **human signal** ‚Üî **context gap**. this isn't a hype deck, a moral panic, or a consulting pdf. this is a map of fractures in our reality."
      ]
    },
    {
      "title": "layer i: foundation",
      "subtitle": "physics, economics, and power",
      "visual": "SECTION_DIVIDER",
      "layout": "center",
      "caption": "shifts 01-03: physical and economic base",
      "dark": true,
      "supertitle": "11 tectonic shifts\nmachines ‚Üî humans across 4 layers",
      "content": [
        "the physical and economic base. energy infrastructure, agentic labor, data sovereignty. **the constraint:** can we power it? can we afford it? who controls it?"
      ]
    },
    {
      "title": "shift 01: the cost ‚Üí physical limits",
      "subtitle": "physics takes revenge. the constraint for 2026 isn't chips; it's \"intelligence per watt.\"",
      "alternativeSubtitle": "We're running out of electricity to power AI. The real limit isn't better chips - it's finding enough energy to run them.",
      "visual": "battery",
      "layout": "shift-scroll",
      "loopNumber": 1,
      "sources": [
        {
          "label": "IEA ‚Äî AI Energy Projections",
          "url": "https://www.iea.org/"
        },
        {
          "label": "Goldman Sachs ‚Äî Investment Gap",
          "url": "https://www.goldmansachs.com/intelligence/pages/gen-ai-too-much-spend-too-little-benefit.html"
        },
        {
          "label": "McKinsey ‚Äî Infrastructure Requirements",
          "url": "https://www.mckinsey.com/"
        },
        {
          "label": "Reuters ‚Äî Nuclear Revival",
          "url": "https://www.reuters.com/"
        }
      ],
      "content": [
        "**The Machine Signal:** AI stopped being an \"ethereal\" cloud. It's concrete, copper, and gigawatts. Demand for compute is growing faster than power grid capacity. Data centers are reopening coal plants and demanding nuclear reactors. **Machine:** **the energy wall:** ai demand for data center power projected to grow **160% by 2030**. the physical grid cannot be built fast enough to support ai expansion. **intelligence/watt:** the focus shifts from raw compute to \"inference efficiency\" as the critical metric. more compute doesn't equal more value if it can't be powered. **Machine Summary:** AI infrastructure is hitting a physical wall: we can't build power grids fast enough to support the compute we're deploying. The bottleneck has shifted from chips to watts. **Human:** **guilt computing:** users face the reality that complex reasoning has a physical toll ‚Äî every ai query consumes water and generates co2. the disconnect between \"green ai\" corporate promises and \"greed ai\" reality. **Human Summary:** Users are becoming aware of AI's physical cost and environmental impact. Environmental guilt is driving awareness, but infrastructure constraints remain the primary bottleneck. **Gap:** the disconnect between infinite \"digital ideas\" and hard \"physical matter.\" while we imagine a billion agents, we cannot power them. this is the bottleneck of the \"dream.\" **the context gap:** the gap between business desire to deploy AI everywhere and the planet's physical inability to support it. **Key Stats:** - **160%:** AI energy demand surge by 2030 (IEA / Goldman Sachs) - **40x:** Gap: $500B infrastructure vs $12B consumer spend (Harvard / Goldman) - **$7T:** Total AI infrastructure requirement (McKinsey / Sam Altman) **Research:** - The physical grid **cannot be built fast enough** to support AI expansion - Focus shifts from raw compute (FLOPs) to **\"Intelligence per Watt\"** as critical metric - Tech giants reviving **decommissioned nuclear reactors** (Three Mile Island for Microsoft) and obsolete fossil fuel plants **Industry Signals:** Microsoft + Three Mile Island, Google Data Centers, AWS Infrastructure, Meta CapEx"
      ]
    },
    {
      "title": "shift 02: the displacement (agentic labor)",
      "subtitle": "from copilot ‚Üí autonomous coworker",
      "alternativeSubtitle": "AI is taking over entire jobs, not just assisting. Companies are replacing hundreds of employees with AI agents that work 24/7.",
      "caption": "when infrastructure exists, labor displacement accelerates.\nwith energy in place, ai moves from labs to production.\nthe constraint was power. now it's human acceptance.",
      "visual": "factory",
      "layout": "shift-scroll",
      "loopNumber": 2,
      "sources": [
        {
          "label": "Klarna ‚Äî AI Assistant Case Study",
          "url": "https://www.klarna.com/international/press/klarna-ai-assistant-handles-two-thirds-of-customer-service-chats-in-its-first-month/"
        },
        {
          "label": "MIT Sloan/BCG ‚Äî Agentic Enterprise",
          "url": "https://sloanreview.mit.edu/projects/the-emerging-agentic-enterprise-how-leaders-must-navigate-a-new-age-of-ai/"
        },
        {
          "label": "SHRM ‚Äî Job Displacement Data",
          "url": "https://www.shrm.org/"
        },
        {
          "label": "McKinsey ‚Äî State of AI",
          "url": "https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai"
        }
      ],
      "content": [
        "**Machine:** **the klarna benchmark:** one ai assistant replaced **700 full-time agents**, slashed resolution time (11m ‚Üí 2m), drove **$40m profit**, and achieved **25% fewer repeat inquiries** than humans. **the agentic enterprise:** transition from \"assistant\" to \"autonomous coworker.\" **76% of executives** view ai as a \"coworker\" rather than a tool. agents receive wallets (x402 protocol), tools (mcp), and \"hr for ai.\" **service-as-software:** saas model shifts to agents that execute complete workflows. from selling \"software licenses\" to selling \"executed outcomes.\" **Human:** **the reliability tax:** **$67 billion** in losses from ai hallucinations and errors. companies shift budgets from \"paying for labor\" to \"paying for audit.\" creating is free; verifying is expensive. **managerial collapse:** predicted **45% reduction in middle management layers** as ai handles coordination. the tension between \"retrofit\" vs \"reengineer.\" **role shift:** humans move from \"doers\" to \"consiglieres\" and auditors. **23.2 million** u.s. jobs directly exposed to ai displacement. **Gap:** when an agent acts, who owns the mistake? managers delegate more than they can audit, creating hidden \"technical debt\" and \"strategic blindness.\" **Key Stats:** - **88% vs 6%:** Adoption rate vs transformation rate - execution gap (McKinsey) - **23.2M:** U.S. jobs highly exposed to displacement (SHRM) - **$40M:** Annual profit from single agentic deployment (Klarna) (Klarna) **Research:** - **$67 billion** annual losses from hallucinations and errors (Reliability Tax) - **76%** of executives viewing AI as \"Coworker\" not tool - **45%** predicted reduction in middle management layers - **32%** of IT jobs have >50% automatable tasks - tech workers most vulnerable **Industry Signals:** Klarna AI Assistant, x402 Protocol, Service-as-Software, Agentic Enterprise"
      ]
    },
    {
      "title": "shift 03: the sovereignty (the splinternet)",
      "subtitle": "from global openness ‚Üí fragmented stacks",
      "alternativeSubtitle": "The internet is splitting into separate zones. Each country wants control over AI - US, China, and Europe are building completely different systems.",
      "caption": "when agents touch money, institutions demand rules.\nwhen agentic labor impacts revenue, nations rush to control infrastructure.\nthe question shifts from \"can ai work?\" to \"whose switch is it?\"",
      "visual": "globe",
      "layout": "shift-scroll",
      "loopNumber": 3,
      "sources": [
        {
          "label": "Leopold Aschenbrenner ‚Äî Situational Awareness",
          "url": "https://situational-awareness.ai/"
        },
        {
          "label": "Marc Andreessen ‚Äî Techno-Optimist Manifesto",
          "url": "https://a16z.com/the-techno-optimist-manifesto/"
        },
        {
          "label": "Balaji Srinivasan ‚Äî Network State",
          "url": "https://thenetworkstate.com/"
        },
        {
          "label": "Wired ‚Äî Privacy Inequality",
          "url": "https://www.wired.com/story/meta-facebook-pay-for-privacy-europe/"
        }
      ],
      "content": [
        "**Machine:** **geopolitical fragmentation - the splinternet:** the end of \"global ai.\" three distinct stacks emerge: **us ai** (corporate/closed - openai, anthropic), **china ai** (state-controlled - deepseek bypassing us norms), **eu ai** (regulated - ai act compliance). agi is now a national security asset on \"war footing.\" **the copyright war - nyt vs. openai:** battle for \"sovereignty of culture.\" nyt lawsuit alleges models **memorize and regurgitate** copyrighted content verbatim. the case determines if human culture belongs to creators or model weights. **eu ai act:** first comprehensive ai regulation. creates **regulatory gap** - eu ai is \"safe but slow,\" us/china ai is \"dangerous but fast.\" **Human:** **the guerrilla stack (byoai):** employees bring their own ai to bypass corporate limitations and censorship. \"shadow ai\" adoption - people use personal tools because corporate ai is blocked or neutered. **privacy inequality:** privacy officially becomes a **luxury good**. meta's \"pay or consent\" model in eu: pay ‚Ç¨13/month or surrender to tracking. \"privacy is for the rich\" - if you can't pay, you are the product. **data sovereignty movement:** users demand \"opt-out\" rights - ability to prohibit training on their data. rise of \"personal rag\" and local-first architectures. **Gap:** as ai becomes \"aligned\" to corporate/national values, you are talking to a constitutional filter. you lose objective context for a \"safe narrative.\" **Key Stats:** - **3%:** Paying users for AI (97% are the product) (Goldman Sachs) - **‚Ç¨13/mo:** Meta's privacy price in Europe (Wired) - **3 Stacks:** US (closed), China (state), EU (regulated) - global AI fragmentation (Multiple) **Research:** - **$200B+** Big Tech CapEx for 2025 alone - **$2.1B** Reddit's data licensing deal with Google - EU AI Act creates first comprehensive regulation - **Regulatory Gap** between \"safe but slow\" vs \"dangerous but fast\" - NYT lawsuit alleges models **memorize and regurgitate** copyrighted content verbatim **Industry Signals:** US AI Stack, China AI Stack, EU AI Act, Network State, Shadow AI"
      ]
    },
    {
      "title": "layer ii: cognition",
      "subtitle": "the architecture of meaning and reason",
      "visual": "SECTION_DIVIDER",
      "layout": "center",
      "caption": "how we think and learn.\nreasoning, knowledge, discovery.",
      "dark": true,
      "content": [
        "**why cognition matters:** with **energy infrastructure**, **agentic labor**, and **geopolitical stacks** in place, ai moves from raw compute to **reasoning capability**. this layer answers three questions: **can we trust how it thinks?** - the reasoning revolution. models shifted from \"fast talkers\" (chatgpt) to \"thinking models\" (o1, deepseek r1). they use test-time compute to generate hidden reasoning chains. but reasoning models are worse at factual accuracy - they reason beautifully about wrong facts. **can we find what we need?** - the context architecture. \"chat with pdf\" is dead. standard is now enterprise rag and mcp (model context protocol) - anthropic's \"usb port for ai\" connecting to all company data. but context obesity is real: consuming more information than you can metabolize into meaning. **can we accelerate discovery?** - generative science. deep research agents read millions of papers overnight and generate hypotheses humans cannot conceive. alphafold 3 predicts protein structures; next step is designing proteins that don't exist in nature. but we face data exhaustion - running out of human-generated text by 2026-2028. **the cognition layer determines what ai can understand** and what humans can verify. the gap: models process 1,000 reasoning steps in seconds; humans can follow maybe five. we accept conclusions because auditing the path exhausts us. the question shifts from \"can we power it?\" to **\"can we trust how it thinks?\"**"
      ]
    },
    {
      "title": "shift 04: the reasoning (the brain)",
      "subtitle": "from chatbots to thinking models",
      "alternativeSubtitle": "AI stopped just answering questions - now it actually thinks through problems step by step, like a human would.",
      "visual": "audit",
      "layout": "shift-scroll",
      "loopNumber": 4,
      "sources": [
        {
          "label": "Sequoia Capital ‚Äî Generative AI Act Two",
          "url": "https://www.sequoiacap.com/article/generative-ai-act-two/"
        },
        {
          "label": "Dario Amodei ‚Äî Machines of Loving Grace",
          "url": "https://darioamodei.com/machines-of-loving-grace"
        },
        {
          "label": "Epoch AI ‚Äî Data Limits",
          "url": "https://epoch.ai/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data"
        },
        {
          "label": "Gretel ‚Äî Synthetic Data",
          "url": "https://gretel.ai/blog/2025-the-year-synthetic-data-goes-mainstream"
        },
        {
          "label": "Shumailov et al. ‚Äî Model Collapse",
          "url": "https://arxiv.org/abs/2305.17493"
        }
      ],
      "content": [
        "**Machine:** **sequoia's act two:** the fundamental shift from \"act 1\" (probabilistic token prediction - chatgpt era) to **\"act 2\"** (reasoning and inference-time compute - o1 era). \"act 1 was about prompts. act 2 is about reasoning.\" **system 1 vs system 2 architecture:** transition from fast, instinctive responses (system 1) to slow, deliberate, multi-step logical reasoning (system 2). models use **chain of thought (cot)** and **star** via reinforcement learning to \"think\" before answering. **scientific compression:** condensing **100 years of scientific progress into 10 years**. prediction: models will exceed nobel-level intelligence in specialized domains (biology, math, physics) by 2026. **Human:** **auditable work:** users no longer trust \"magic\" speed. they demand to see the **reasoning trace** - the chain of thought that led to the conclusion. transparency over velocity. **logic auditor role:** human value shifts from execution to **verifying machine logic**. we become auditors of ai reasoning paths. **the reasoning reliability gap:** **48% of reasoning tasks** still produce errors in complex scenarios. reasoning models haven't eliminated hallucinations - they've made them more convincing. **Gap:** a model processes 1,000 reasoning steps in seconds; a human follows five. this leads to meaning dilution: we accept conclusions because auditing the path is too exhausting. **Key Stats:** - **126%:** Productivity boost from AI Copilots (Qodo) - **21%:** Quality degradation when prioritizing speed (Nielsen Norman Group) - **48%:** Error rate in complex reasoning tasks (Korra AI) **Research:** - **2026-2028:** Human data exhaustion timeline (Epoch AI) - **100 ‚Üí 10 years:** Scientific compression timeline (Amodei) - Models use **Chain of Thought (CoT)** and **STaR** via reinforcement learning - **o3** achieves 71.7% on SWE-bench Verified, 96.7% on AIME math benchmark **Industry Signals:** OpenAI o3, DeepSeek R1, Claude 3.7 Sonnet, Gemini 2.0 **Machine:** **deep research agents:** ai reads millions of papers to generate hypotheses humans cannot conceive. from \"literature review\" to \"hypothesis generation.\" **generative biology:** moving from \"reading\" biology to \"writing\" it. alphafold 3 predicts protein structures; next step is **designing** new proteins, materials, and molecules that don't exist in nature. **data limits - the exhaustion:** quality human-generated data **exhausted by 2026-2028**. models now train on **ai-generated synthetic data**, verified by system 2 reasoning. **Human:** **the time refund:** scientists freed from tedious manual labor (literature review, data cleaning) to focus on high-level experimental design and cross-domain synthesis. **data inbreeding crisis:** without fresh human data, ai degrades. **humans become the only source of novelty** - the \"organic data\" that prevents model collapse. human creativity is now a strategic resource. **the hope/fear axis:** hope for longevity breakthroughs and disease cures vs fear of losing control over scientific truth and safety protocols. **Gap:** ai proposes 1,000 molecules; we test one. discovery bloat stalls breakthroughs via physical testing capacity. the bottleneck of \"generated future.\" **Key Stats:** - **100 ‚Üí 10:** Scientific progress compression timeline (years) (Dario Amodei) - **78%:** Improvement in research speed with AI tools (StackOverflow) - **2026-2028:** Human data exhaustion timeline (Epoch AI) **Research:** - AlphaFold 3 predicts protein structures - next step is **designing** new proteins that don't exist in nature - Models now train on **AI-generated synthetic data**, verified by System 2 reasoning - **Model Collapse** (Shumailov et al.): if AI trains on AI-generated data recursively, models degrade - humans become only source of \"clean signal\" - 1,000:1 ratio: AI proposes 1,000 molecules; humans test one - the verification bottleneck **Industry Signals:** DeepMind AlphaFold, Deep Research Agents, Synthetic Data, World Labs"
      ]
    },
    {
      "title": "layer iii: interface",
      "subtitle": "craft, matter, and defense",
      "visual": "SECTION_DIVIDER",
      "layout": "center",
      "caption": "how we build and protect.\ncoding, matter, defense.",
      "dark": true,
      "content": [
        "**why interface matters:** with reasoning, knowledge access, and discovery capabilities, ai moves from **abstract intelligence to practical execution**. this layer answers three questions: **can we maintain what we build?** - the coding revolution. code became commodity. amazon q saved 4,500 developer-years on java upgrades. 65% of code is ai-influenced at major companies. but integrity crisis emerges: \"code generation easy, code integrity hard.\" 46% of developers distrust ai code. we create legacy on day one. **can we bridge digital and physical?** - spatial intelligence. ai learns 3d space and physics, not just pixels. foundation models for the physical world. robots that understand spatial relationships. embodied ai moves from simulation to reality. but the sim-to-real gap remains: what works in simulation often fails in the real world. **can we defend against what we create?** - the security paradox. ai accelerates both attack and defense. 87% of organizations experiencing ai-driven attacks. deepfakes, prompt injection, model poisoning. but ai also powers detection systems. the arms race accelerates. **the interface layer determines what ai can build** and what humans can control. the gap: machines operate at machine speed, but accountability remains human speed. we can generate code faster than we can understand it. the question shifts from \"can it think?\" to **\"can it ship?\"**"
      ]
    },
    {
      "title": "shift 07: the craft (the end of syntax)",
      "subtitle": "from writing code to architecting intent",
      "alternativeSubtitle": "You no longer need to know how to code. Just describe what you want in plain English, and AI writes the software for you.",
      "visual": "centaur",
      "layout": "shift-scroll",
      "loopNumber": 7,
      "sources": [
        {
          "label": "GitHub ‚Äî Copilot Impact Report",
          "url": "https://github.blog/news-insights/research/research-quantifying-github-copilots-impact-on-code-quality/"
        },
        {
          "label": "Amazon ‚Äî Q Developer Savings",
          "url": "https://aws.amazon.com/blogs/aws/amazon-q-developer-agent-capabilities/"
        },
        {
          "label": "StackOverflow ‚Äî Developer Survey 2025",
          "url": "https://survey.stackoverflow.co/2025/ai"
        }
      ],
      "content": [
        "**Machine:** **code as commodity:** **65% of new code** is ai-influenced or ai-generated at companies like google. **73% of developers** use ai coding tools regularly. **amazon q developer:** saved **4,500 developer-years** on java application upgrades. **$260m** in infrastructure savings from optimized code. **79% of auto-generated changes** accepted without modification. **vibe coding:** programming shifts to natural language intent. the machine handles implementation. coding tools (cursor, replit) enter **top 100 gen ai apps** consumer ranking - coding becomes mass-market. **Human:** **the trust collapse:** **46% of developers** distrust ai-generated code. only **3.1% highly trust** ai accuracy for complex tasks. the **trust inversion**: 84% use the tools, but trust is plummeting. **the integrity crisis:** **65% report ai misses context** in code generation. \"code generation is easy, code integrity is hard.\" ai creates \"legacy on day one\" - code that works but is unmaintainable. **code churn explosion:** **50% increase** in code churn (rewrites and deletions). ai produces code fast, but developers spend saved time on reviews and fixes. **Gap:** building things we don't understand leads to vibe debt. we pilot ships with black-box internal wiring. creating code is easy; maintaining it is the new hell. **Key Stats:** - **65%:** New code is AI-influenced or AI-generated at companies like Google - **73%:** Developers using AI coding tools regularly - **46%:** Developers distrust AI-generated code (only 3.1% highly trust) **Research:** - **Amazon Q Developer:** saved 4,500 developer-years, $260M in infrastructure savings - **79%** of auto-generated changes accepted without modification - **50% increase** in code churn (rewrites and deletions) - **65%** report AI misses context in code generation **Industry Signals:** Cursor, GitHub Copilot, Replit Agent, Amazon Q Developer, Vibe Coding"
      ]
    },
    {
      "title": "shift 08: on-device models ‚Üî privacy as status",
      "subtitle": "smaller models get good enough and spread everywhere.",
      "alternativeSubtitle": "AI is moving onto your phone and laptop. No more sending your data to the cloud - everything runs locally and privately.",
      "visual": "unlocked",
      "layout": "shift-scroll",
      "loopNumber": 8,
      "sources": [
        {
          "label": "Android ‚Äî Gemini Nano on-device APIs",
          "url": "https://android-developers.googleblog.com/2025/08/the-latest-gemini-nano-with-on-device-ml-kit-genai-apis.html"
        },
        {
          "label": "Wired ‚Äî Meta Pay for Privacy",
          "url": "https://www.wired.com/story/meta-facebook-pay-for-privacy-europe/"
        },
        {
          "label": "ChinaTalk ‚Äî Chinese AI 2025",
          "url": "https://www.chinatalk.media/p/china-ai-in-2025-wrapped"
        }
      ],
      "content": [
        "**Machine:** ai becomes ambient ‚Äî less a destination, more a layer. on devices, at the edge, inside apps. smaller models get good enough. **Human:** **privacy becomes status:** not secrecy ‚Äî **control**. more private drafting, smaller circles, local storage, intentional friction against performative posting. **hardware sovereignty:** shift to on-device ai to decouple from cloud dependency. **privacy and cost are the primary drivers** - users want control over their data and want to avoid cloud subscription fees. latency improvements and energy independence are side benefits. **Gap:** when ai is everywhere, boundaries become the differentiator. **if everything can be processed, the premium shifts to what you keep.** **Key Stats:** - **30%:** Chinese open-source LLM global share (from 1.2%) (ChinaTalk 2025) - **90-95%:** DeepSeek cost reduction vs OpenAI o1 (DeepSeek 2025) - **10M+:** Qwen app downloads in one week (Alibaba 2025) **Research:** - **Gemini Nano** on-device: AI becomes ambient, not destination - Meta \"pay for privacy\" model in Europe ‚Äì **control as premium** - Local-first: private drafting, smaller circles, intentional friction **Industry Signals:** Gemini Nano, Apple Intelligence, DeepSeek R1, Local LLMs"
      ]
    },
    {
      "title": "shift 09: machine intimacy + programmable identity",
      "alternativeSubtitle": "People are forming real emotional bonds with AI companions. It's not just a tool anymore - it's becoming a relationship.",
      "caption": "when AI is everywhere, relationships become possible.\nas models move on-device, the relationship changes from tool to companion.\nconstant access + privacy + personalization = emotional adoption.",
      "subtitle": "ai moves from tool to relationship surface.",
      "visual": "echo",
      "layout": "shift-scroll",
      "loopNumber": 9,
      "sources": [
        {
          "label": "Ada Lovelace Institute ‚Äî AI Companions",
          "url": "https://www.adalovelaceinstitute.org/blog/ai-companions/"
        },
        {
          "label": "AI Mindset ‚Äî Mental Health Boundaries",
          "url": "https://aimindsetspace.substack.com/p/founder-os-mental-health"
        },
        {
          "label": "Marwick & Boyd ‚Äî Context Collapse",
          "url": "https://www.microsoft.com/en-us/research/publication/i-tweet-honestly-i-tweet-passionately-twitter-users-context-collapse-and-the-imagined-audience/"
        }
      ],
      "content": [
        "**Machine:** companions, therapists, griefbots, parasocial loops. in parallel, ai makes it easy to produce a \"professional self\" at scale ‚Äî identity becomes programmable. **Human:** loneliness isn't solved by information. people accept synthetic intimacy (even while knowing it's synthetic). meanwhile, people tire of performing the self; they retreat to private spaces and smaller audiences. **Gap:** humans outsource emotional regulation to systems optimized for engagement. **we confuse \"attention\" with \"care.\"** **Key Stats:** - **87%:** Organizations attacked with AI-assisted threats (Cybersecurity surveys) - **$12.5B:** US financial fraud losses (2025) (FTC 2025) - **95%:** GenAI pilots failing to deliver ROI (MIT) (MIT 2025) **Research:** - **Parasocial AI**: companions, therapists, griefbots normalized - \"Context collapse\" ‚Äì same identity, different audiences - People accept synthetic intimacy **while knowing it is synthetic** **Industry Signals:** AI companions, Replika, Character.AI, Deepfakes"
      ]
    },
    {
      "title": "constraint tracks",
      "subtitle": "the limits that govern all waves",
      "visual": "SECTION_DIVIDER",
      "layout": "center",
      "caption": "these don't follow from the chain ‚Äî they constrain everything.",
      "dark": true
    },
    {
      "title": "shift 10: data wall",
      "subtitle": "high-quality human data is finite; marginal gains get expensive.",
      "alternativeSubtitle": "We're running out of quality content to train AI on. The internet has been scraped dry, and AI is now training on AI-generated content.",
      "visual": "barrier",
      "layout": "shift-scroll",
      "loopNumber": 10,
      "sources": [
        {
          "label": "Epoch AI ‚Äî Limits of LLM Scaling",
          "url": "https://epoch.ai/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data"
        },
        {
          "label": "Shumailov et al. ‚Äî Model Collapse",
          "url": "https://arxiv.org/abs/2305.17493"
        },
        {
          "label": "Korra ‚Äî $67B AI Hallucination Warning",
          "url": "https://korra.ai/the-67-billion-warning-how-ai-hallucinations-hurt-enterprises-and-how-to-stop-them/"
        },
        {
          "label": "ISACA ‚Äî AI Pitfalls 2025",
          "url": "https://www.isaca.org/resources/news-and-trends/isaca-now-blog/2025/avoiding-ai-pitfalls-in-2026-lessons-learned-from-top-2025-incidents"
        }
      ],
      "content": [
        "**Machine:** training leans harder on synthetic data and distillation. as synthetic output floods the environment, \"evidence\" becomes a formatting problem: it can look right before it is right. **Human:** trust becomes scarce. people shift from \"is it true?\" to \"is it traceable?\" the new literacy is **provenance**. **Gap:** machines can manufacture infinite text and images. humans can't manufacture infinite meaning. **the ratio collapses.** **Key Stats:** - **$67.4B:** Global enterprise losses from AI hallucinations (Korra 2025) - **47%:** Business leaders making decisions on hallucinated output (Industry surveys) - **0.7%:** Best hallucination rate (Gemini 2.0 Flash) (ISACA 2025) **Research:** - **Model Collapse**: training on synthetic data degrades quality over generations - Four models now achieve **sub-1% hallucination rates** - \"Is it true?\" shifting to \"**is it traceable?**\" ‚Äì provenance as new literacy **Industry Signals:** Synthetic data, Model collapse, RAG systems, Data provenance"
      ]
    },
    {
      "title": "shift 11: compute & energy ‚Üî return of physics",
      "subtitle": "ai isn't just software. it's infrastructure.",
      "alternativeSubtitle": "AI needs massive amounts of electricity and physical hardware. It's not just code anymore - it's power plants, chips, and cooling systems.",
      "visual": "pulse",
      "layout": "shift-scroll",
      "loopNumber": 11,
      "dark": true,
      "sources": [
        {
          "label": "Goldman Sachs ‚Äî AI Power Demand",
          "url": "https://www.goldmansachs.com/insights/articles/ai-to-drive-165-increase-in-data-center-power-demand-by-2030"
        },
        {
          "label": "McKinsey ‚Äî Cost of Compute",
          "url": "https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/the-cost-of-compute-a-7-trillion-dollar-race-to-scale-data-centers"
        },
        {
          "label": "IEA ‚Äî Energy Supply for AI",
          "url": "https://www.iea.org/reports/energy-and-ai/energy-supply-for-ai"
        }
      ],
      "content": [
        "**Machine:** chips, energy, cooling, geopolitics. even digital gods need electricity. energy and compute become the regulator of progress. **Human:** energy economics turns personal: burnout realism, fatigue, \"time hangover,\" sharper awareness of biological limits. people begin optimizing for sustainability, not maximum output. **Gap:** data centres become local political issues; your \"cloud\" starts to feel like a land dispute. philosophical note: thermodynamics returns as a hidden governor ‚Äî you can't out-optimize scarcity forever. **Key Stats:** - **$315-371B:** Hyperscaler CapEx 2025 (+40-44% YoY) (Goldman Sachs) - **536 TWh:** Data center electricity consumption 2025 (IEA) - **$7.9T:** Estimated AI infrastructure CapEx to 2030 (McKinsey) **Research:** - **7-year wait** for some power grid connection requests - Stargate project: **$500B** investment over 4 years - Data centres become local political issues; \"cloud\" feels like land dispute **Industry Signals:** Stargate, NVIDIA, AMD, Power grid, Nuclear"
      ]
    },
    {
      "title": "machines, summarized (2025 ‚Üí 2026)",
      "subtitle": "what changed in machines:",
      "visual": "velocity",
      "layout": "split",
      "content": [
        "from chat to **delegation** (agents + orchestration) from \"more scale\" to **better reasoning** (system-2 behavior) from capability focus to **constraints** (trust, governance, energy) from one platform to **protocol layers** (connective tissue) from cloud-only to **ambient ai** (on-device + edge)"
      ]
    },
    {
      "title": "humans, summarized (2025 ‚Üí 2026)",
      "subtitle": "what changed in humans:",
      "visual": "balance",
      "layout": "split",
      "content": [
        "from consumption to **curation** (feeds ‚Üí gardens) from optimism to **trust management** (provenance, receipts, auditability) from public posting to **private coherence** (smaller circles, intentional friction) from \"more tools\" to **more fatigue** (capacity gap) from \"identity as output\" to **identity as constraint**"
      ]
    },
    {
      "title": "call to agency",
      "subtitle": "the wrong question is: \"what is this doing to us?\"",
      "visual": "spark",
      "layout": "center",
      "dark": true,
      "content": [
        "the better question is: **\"what are we letting it do to us?\"** this is not a technological coup. it's a voluntary abdication ‚Äî a surrender of the burden of choice. it can be reclaimed. but it must be reclaimed."
      ]
    },
    {
      "title": "survival kit",
      "subtitle": "in 2026, most people won't lose to ai. they'll lose to their own defaults.",
      "visual": "grid",
      "layout": "split",
      "content": [
        "your life already runs on configuration: what you say yes to without thinking what interrupts you without permission what you outsource because you're tired what you believe because it was repeated **constitution-as-code** = moving from \"i'll try\" ‚Üí \"i have defaults.\" a config file for your life."
      ]
    },
    {
      "title": "community signals",
      "subtitle": "field signals: real workflow shifts from ai mindset space",
      "visual": "SECTION_DIVIDER",
      "layout": "center",
      "caption": "that ground our 10 waves in lived experience."
    },
    {
      "title": "field signals",
      "subtitle": "real workflow shifts from the community",
      "visual": "MULTI_QUOTES",
      "layout": "quotes"
    },
    {
      "title": "more field signals",
      "subtitle": "continued reflections from the community",
      "visual": "MULTI_QUOTES",
      "layout": "quotes"
    },
    {
      "title": "stay in the loop",
      "subtitle": "if this artifact helped you name the friction ‚Äî don't lose the thread.",
      "visual": "LINKS_QR",
      "layout": "split",
      "content": [
        "stay connected with ai mindset: **subscribe on substack** ‚Üí get next resets, field notes, templates, and lab openings **explore the ecosystem** ‚Üí labs, tools, community, artifacts **talk to us** ‚Üí partnerships / speaking / labs for teams _signals only. no spam. unsubscribe anytime._"
      ]
    },
    {
      "title": "source shelf (curated)",
      "subtitle": "the full reading list behind this report",
      "visual": "SECTION_DIVIDER",
      "layout": "center"
    },
    {
      "title": "ai: capability, infra, adoption",
      "subtitle": "core references",
      "visual": "source",
      "layout": "sources",
      "sources": [
        {
          "label": "Stanford HAI ‚Äî AI Index 2025 (PDF)",
          "url": "https://hai-production.s3.amazonaws.com/files/hai_ai_index_report_2025.pdf"
        },
        {
          "label": "Gartner ‚Äî Top 10 Strategic Technology Trends for 2025",
          "url": "https://www.gartner.com/en/newsroom/press-releases/2024-10-21-gartner-identifies-the-top-10-strategic-technology-trends-for-2025"
        },
        {
          "label": "Anthropic ‚Äî Model Context Protocol (MCP)",
          "url": "https://www.anthropic.com/news/model-context-protocol"
        },
        {
          "label": "MCP Spec Hub",
          "url": "https://modelcontextprotocol.io/"
        },
        {
          "label": "SWE-bench Ecosystem",
          "url": "https://www.swebench.com/"
        },
        {
          "label": "OpenAI ‚Äî Introducing SWE-bench Verified",
          "url": "https://openai.com/index/introducing-swe-bench-verified/"
        },
        {
          "label": "X402 ‚Äî Internet-native payments for AI agents",
          "url": "https://www.x402.org/"
        }
      ]
    },
    {
      "title": "data: limits + synthetic loops",
      "subtitle": "on the data wall",
      "visual": "signal",
      "layout": "sources",
      "sources": [
        {
          "label": "Epoch AI ‚Äî Limits of LLM Scaling (Human Data Constraints)",
          "url": "https://epoch.ai/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data"
        },
        {
          "label": "Shumailov et al. ‚Äî The Curse of Recursion / Model Collapse",
          "url": "https://arxiv.org/abs/2305.17493"
        }
      ]
    },
    {
      "title": "humans: overload, trust, culture",
      "subtitle": "the human layer",
      "visual": "noise",
      "layout": "sources",
      "sources": [
        {
          "label": "Microsoft ‚Äî Work Trend Index 2024",
          "url": "https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is-here-now-comes-the-hard-part"
        },
        {
          "label": "Microsoft ‚Äî Work Trend Index 2025",
          "url": "https://www.microsoft.com/en-us/worklab/work-trend-index/2025-the-year-the-frontier-firm-is-born"
        },
        {
          "label": "Edelman ‚Äî 2025 Trust Barometer (Global Report, PDF)",
          "url": "https://www.edelman.com/sites/g/files/aatuss191/files/2025-01/2025%20Edelman%20Trust%20Barometer_Final.pdf"
        },
        {
          "label": "Marwick & Boyd ‚Äî Context Collapse / Imagined Audience",
          "url": "https://www.microsoft.com/en-us/research/publication/i-tweet-honestly-i-tweet-passionately-twitter-users-context-collapse-and-the-imagined-audience/"
        },
        {
          "label": "Wired ‚Äî Meta is asking people in Europe to pay for privacy",
          "url": "https://www.wired.com/story/meta-facebook-pay-for-privacy-europe/"
        },
        {
          "label": "ICO ‚Äî Data Lives: Year 2 Report (PDF)",
          "url": "https://ico.org.uk/media2/m2maphry/ico-data-lives-year-2-report.pdf"
        }
      ]
    },
    {
      "title": "governance / philosophy",
      "subtitle": "policy and thought",
      "visual": "search",
      "layout": "sources",
      "sources": [
        {
          "label": "EUR-Lex ‚Äî AI Act (Regulation (EU) 2024/1689)",
          "url": "https://eur-lex.europa.eu/eli/reg/2024/1689/oj/eng"
        },
        {
          "label": "European Commission ‚Äî AI Research Publications in Science",
          "url": "https://op.europa.eu/en/publication-detail/-/publication/4ee8799e-142c-11f0-b1a3-01aa75ed71a1/language-en"
        },
        {
          "label": "TU Wien ‚Äî Perspectives on Digital Humanism",
          "url": "https://dighum.ec.tuwien.ac.at/perspectives-on-digital-humanism/"
        },
        {
          "label": "Pew Research ‚Äî Trust in the EU, U.S. and China to Regulate AI (2025)",
          "url": "https://www.pewresearch.org/2025/10/15/trust-in-the-eu-u-s-and-china-to-regulate-use-of-ai/"
        },
        {
          "label": "Ouyang et al. ‚Äî InstructGPT (2022)",
          "url": "https://arxiv.org/abs/2203.02155"
        },
        {
          "label": "Bai et al. ‚Äî Constitutional AI (2022)",
          "url": "https://arxiv.org/abs/2212.08073"
        },
        {
          "label": "Investigating Local Censorship (ArXiv, 2025)",
          "url": "https://arxiv.org/pdf/2505.12625"
        },
        {
          "label": "Digital Plurality Project",
          "url": "https://github.com/pluralitybook/plurality"
        }
      ]
    },
    {
      "title": "frame: attention, cognition, acceleration, sovereignty",
      "subtitle": "foundational thinkers",
      "visual": "growth",
      "layout": "sources",
      "sources": [
        {
          "label": "Simon ‚Äî Designing Organizations for an Information-Rich World (1971, PDF)",
          "url": "https://www.nmh-p.de/wp-content/uploads/Simon-H.A._Designing-organizations-for-an-information-rich-world.pdf"
        },
        {
          "label": "Wu ‚Äî The Attention Merchants",
          "url": "https://www.penguinrandomhouse.com/books/234876/the-attention-merchants-by-tim-wu/"
        },
        {
          "label": "Sweller ‚Äî Cognitive Load During Problem Solving (1988)",
          "url": "https://www.sciencedirect.com/science/article/pii/0364021388900237"
        },
        {
          "label": "Mark et al. ‚Äî Focused, Aroused, But So Distractible",
          "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/10/p903-mark.pdf"
        },
        {
          "label": "Kahneman ‚Äî Thinking, Fast and Slow",
          "url": "https://us.macmillan.com/books/9780374533557/thinkingfastandslow/"
        },
        {
          "label": "Toffler ‚Äî Future Shock",
          "url": "https://search.library.wisc.edu/catalog/999466643102121/cite"
        },
        {
          "label": "Rosa ‚Äî Social Acceleration",
          "url": "https://cup.columbia.edu/book/social-acceleration/9780231148344/"
        },
        {
          "label": "Clark & Chalmers ‚Äî The Extended Mind",
          "url": "https://consc.net/papers/extended.html"
        },
        {
          "label": "Shneiderman ‚Äî Human-Centered AI",
          "url": "https://global.oup.com/academic/product/human-centered-ai-9780192845290"
        },
        {
          "label": "Hirschman ‚Äî Exit, Voice, and Loyalty",
          "url": "https://www.hup.harvard.edu/books/9780674276604"
        },
        {
          "label": "Davidson & Rees-Mogg ‚Äî The Sovereign Individual",
          "url": "https://www.simonandschuster.com/books/The-Sovereign-Individual/James-Dale-Davidson/9781797103389"
        },
        {
          "label": "Srinivasan ‚Äî The Network State",
          "url": "https://thenetworkstate.com/"
        }
      ]
    },
    {
      "title": "machine intimacy",
      "subtitle": "on ai companions",
      "visual": "echo",
      "layout": "sources",
      "sources": [
        {
          "label": "Ada Lovelace Institute ‚Äî Friends for Sale: The Rise and Risks of AI Companions (2025)",
          "url": "https://www.adalovelaceinstitute.org/blog/ai-companions/"
        }
      ]
    },
    {
      "title": "ai mindset field notes",
      "subtitle": "our own publications referenced in this deck",
      "visual": "spark",
      "layout": "sources",
      "sources": [
        {
          "label": "You're not burned out, you've got context obesity",
          "url": "https://hackernoon.com/youre-not-burned-out-youve-got-context-obesity"
        },
        {
          "label": "Team Knowledge System (AI Ark)",
          "url": "https://aimindsetspace.substack.com/p/ai-ark-knowledge-system"
        },
        {
          "label": "Coding with Claude 3.5",
          "url": "https://t.me/ai_mind_set/282"
        },
        {
          "label": "AI + Mental Health Boundaries (Founder OS)",
          "url": "https://aimindsetspace.substack.com/p/founder-os-mental-health"
        }
      ]
    },
    {
      "title": "11 / lab evidence & credibility",
      "subtitle": "hardened by the field notes of 1,500+ lab participants.",
      "visual": "STATS_ANIMATED",
      "layout": "stats",
      "content": [
        "this report is hardened by the field notes and artifacts of our research: **ivanov.aimindset.org** ‚Äî protecting the psyche in the age of machine intimacy. **intention.aimindset.org** ‚Äî managing attention when context explodes. **spiridonov.aimindset.org** ‚Äî why pragmatic romanticism is the only defense against cold machine logic."
      ]
    },
    {
      "title": "thank you",
      "subtitle": "the context gap ¬∑ annual report 2025",
      "visual": "SPARKLE_FINALE",
      "layout": "center",
      "dark": true,
      "content": [
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ this is not about keeping up with machines. it's about building operating systems for humans. ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ created with the ai mindset labs community alex p ¬∑ ray svitla ¬∑ sergei khabarov ¬∑ anca"
      ]
    }
  ]
}